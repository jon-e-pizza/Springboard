{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning\n",
    "After an initial exploratory analysis of variables that could relate to success of fast food establishments in an area, we will now use machine learning techniques to see if we can extract additional insights about what areas we should pay attention to and what features we should prioritize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# required imports for our analysis\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# load our summary dataset on fast food establishments in Philadelphia\n",
    "ff_cbg_data = pd.read_csv('location_data_wrangled.csv', index_col=0)\n",
    "\n",
    "# And begin by filtering to CBGS with fast food consumer observations\n",
    "ff_cbg_data = ff_cbg_data[ff_cbg_data['Fast Food Count'] != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Total Population', 'Pop. that Works from Home',\n",
       "       'Single Occupant Households', 'Single Parent Households',\n",
       "       'Married Parent Households', 'Undergrads and Grads',\n",
       "       'Diploma/GED attained', 'Degree attained', 'Households in Poverty',\n",
       "       'Below 40k Earners', '40k-100k Earners', 'Above 100k Earners',\n",
       "       'Unemployed', 'Renter Occupied Households', 'Owner Occupied Households',\n",
       "       'Crime Counts', 'walk_score', 'transit_score', 'Fast Food Count',\n",
       "       'Fast Food Consumers', 'raw_visit_count'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Our features\n",
    "ff_cbg_data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to distinguish what sets an area apart as a particularly successful area. Lets check the distribution of consumers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([67., 56., 23., 10.,  5.,  5.,  7.,  1.,  3.,  2.,  0.,  1.,  0.,\n",
       "         0.,  1.,  0.,  0.,  1.,  1.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,\n",
       "         1.,  0.,  0.,  2.]),\n",
       " array([6.00000e+00, 4.18500e+02, 8.31000e+02, 1.24350e+03, 1.65600e+03,\n",
       "        2.06850e+03, 2.48100e+03, 2.89350e+03, 3.30600e+03, 3.71850e+03,\n",
       "        4.13100e+03, 4.54350e+03, 4.95600e+03, 5.36850e+03, 5.78100e+03,\n",
       "        6.19350e+03, 6.60600e+03, 7.01850e+03, 7.43100e+03, 7.84350e+03,\n",
       "        8.25600e+03, 8.66850e+03, 9.08100e+03, 9.49350e+03, 9.90600e+03,\n",
       "        1.03185e+04, 1.07310e+04, 1.11435e+04, 1.15560e+04, 1.19685e+04,\n",
       "        1.23810e+04]),\n",
       " <a list of 30 Patch objects>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAD7CAYAAABzGc+QAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAQmklEQVR4nO3dbYxmZX3H8e+vuyKK2t2VgWxBupAQKr4Q6AShNMaCWAQjNNEGYsxWMZvUh2htokt90Zr0xaJNfUgbdYPabYMIInYJRC3ZQtomzeoiiOBCd0GKK1t2UKnWJlX03xf3tTA7O7Nzz8M9M9fy/SR3zjnXOWfmf51zz2/PfR7uTVUhSerPry13AZKk+THAJalTBrgkdcoAl6ROGeCS1CkDXJI6NWuAJzkjyb2TXj9J8r4k65LckWRPG65dioIlSQOZy33gSVYBPwBeBbwL+FFVbUmyGVhbVR8cTZmSpKnmGuCvA/68qi5I8hDwmqran2Q9cFdVnXGk9Y8//vjasGHDggqWpOeau++++8mqGpvavnqOP+dK4IY2fmJV7QdoIX7CdCsk2QRsAjjllFPYtWvXHH+lJD23JfnP6dqHvoiZ5BjgjcCX5vKLq2prVY1X1fjY2GH/gEiS5mkud6G8HvhWVT3Rpp9op05owwOLXZwkaWZzCfCrePb0CcCtwMY2vhHYvlhFSZJmN1SAJ3khcDFwy6TmLcDFSfa0eVsWvzxJ0kyGuohZVf8LvHRK2w+Bi0ZRlCRpdj6JKUmdMsAlqVMGuCR1ygCXpE7N9UnMZbNh8+1DLffolstGXIkkrQwegUtSpwxwSeqUAS5JnTLAJalTBrgkdcoAl6ROGeCS1CkDXJI6ZYBLUqcMcEnqlAEuSZ0ywCWpUwa4JHXKAJekThngktQpA1ySOmWAS1KnhgrwJGuS3JzkwSS7k5yfZF2SO5LsacO1oy5WkvSsYY/APwF8rap+C3glsBvYDOyoqtOBHW1akrREZg3wJC8BXg18FqCqfl5VTwGXA9vaYtuAK0ZVpCTpcMMcgZ8GTACfT3JPkuuSHAecWFX7AdrwhOlWTrIpya4kuyYmJhatcEl6rhsmwFcD5wCfqqqzgZ8xh9MlVbW1qsaranxsbGyeZUqSphomwPcB+6pqZ5u+mUGgP5FkPUAbHhhNiZKk6cwa4FX1X8D3k5zRmi4CvgvcCmxsbRuB7SOpUJI0rdVDLvce4PokxwCPAG9jEP43JbkaeAx482hKlCRNZ6gAr6p7gfFpZl20uOVIkoblk5iS1CkDXJI6ZYBLUqcMcEnqlAEuSZ0ywCWpUwa4JHVq2Ad5urFh8+1DLffolstGXIkkjZZH4JLUKQNckjplgEtSpwxwSeqUAS5JnTLAJalTBrgkdcoAl6ROGeCS1CkDXJI6ZYBLUqcMcEnqlAEuSZ0ywCWpU0N9nWySR4GfAr8Enq6q8STrgBuBDcCjwB9W1Y9HU6Ykaaq5HIH/XlWdVVXjbXozsKOqTgd2tGlJ0hJZyCmUy4FtbXwbcMXCy5EkDWvYAC/gn5LcnWRTazuxqvYDtOEJ062YZFOSXUl2TUxMLLxiSRIw/H+pdkFVPZ7kBOCOJA8O+wuqaiuwFWB8fLzmUaMkaRpDHYFX1eNteAD4CnAu8ESS9QBteGBURUqSDjdrgCc5LsmLD44DrwPuB24FNrbFNgLbR1WkJOlww5xCORH4SpKDy3+hqr6W5JvATUmuBh4D3jy6MiVJU80a4FX1CPDKadp/CFw0iqIkSbPzSUxJ6pQBLkmdMsAlqVMGuCR1ygCXpE4Z4JLUKQNckjplgEtSpwxwSeqUAS5JnTLAJalTBrgkdcoAl6ROGeCS1CkDXJI6ZYBLUqcMcEnqlAEuSZ0ywCWpUwa4JHXKAJekThngktSpoQM8yaok9yS5rU2fmmRnkj1JbkxyzOjKlCRNNZcj8PcCuydNXwt8rKpOB34MXL2YhUmSjmyoAE9yMnAZcF2bDnAhcHNbZBtwxSgKlCRNb9gj8I8DHwB+1aZfCjxVVU+36X3ASdOtmGRTkl1Jdk1MTCyoWEnSs2YN8CRvAA5U1d2Tm6dZtKZbv6q2VtV4VY2PjY3Ns0xJ0lSrh1jmAuCNSS4FjgVewuCIfE2S1e0o/GTg8dGVKUmaatYj8Kq6pqpOrqoNwJXAP1fVW4A7gTe1xTYC20dWpSTpMAu5D/yDwPuT7GVwTvyzi1OSJGkYw5xCeUZV3QXc1cYfAc5d/JIkScPwSUxJ6pQBLkmdMsAlqVMGuCR1ygCXpE4Z4JLUKQNckjplgEtSpwxwSeqUAS5JnTLAJalTBrgkdcoAl6ROGeCS1CkDXJI6ZYBLUqcMcEnqlAEuSZ0ywCWpUwa4JHXKAJekThngktSpWQM8ybFJvpHk20keSPLh1n5qkp1J9iS5Mckxoy9XknTQMEfg/wdcWFWvBM4CLklyHnAt8LGqOh34MXD16MqUJE01a4DXwP+0yee1VwEXAje39m3AFSOpUJI0raHOgSdZleRe4ABwB/Aw8FRVPd0W2QecNMO6m5LsSrJrYmJiMWqWJDFkgFfVL6vqLOBk4Fzg5dMtNsO6W6tqvKrGx8bG5l+pJOkQc7oLpaqeAu4CzgPWJFndZp0MPL64pUmSjmSYu1DGkqxp4y8AXgvsBu4E3tQW2whsH1WRkqTDrZ59EdYD25KsYhD4N1XVbUm+C3wxyV8C9wCfHWGdkqQpZg3wqroPOHua9kcYnA+XJC0Dn8SUpE4Z4JLUKQNckjplgEtSpwxwSeqUAS5JnTLAJalTBrgkdcoAl6ROGeCS1CkDXJI6ZYBLUqcMcEnqlAEuSZ0ywCWpUwa4JHVqmP+R56i0YfPtQy336JbLRlyJJM2PR+CS1CkDXJI6ZYBLUqcMcEnqlAEuSZ2aNcCTvCzJnUl2J3kgyXtb+7okdyTZ04ZrR1+uJOmgYY7Anwb+tKpeDpwHvCvJmcBmYEdVnQ7saNOSpCUya4BX1f6q+lYb/ymwGzgJuBzY1hbbBlwxqiIlSYeb0znwJBuAs4GdwIlVtR8GIQ+cMMM6m5LsSrJrYmJiYdVKkp4xdIAneRHwZeB9VfWTYderqq1VNV5V42NjY/OpUZI0jaECPMnzGIT39VV1S2t+Isn6Nn89cGA0JUqSpjPMXSgBPgvsrqq/njTrVmBjG98IbF/88iRJMxnmy6wuAN4KfCfJva3tz4AtwE1JrgYeA948mhIlSdOZNcCr6t+AzDD7osUtR5I0LJ/ElKROGeCS1CkDXJI6ZYBLUqcMcEnqlAEuSZ0ywCWpUwa4JHXKAJekThngktQpA1ySOmWAS1KnDHBJ6pQBLkmdMsAlqVMGuCR1ygCXpE4Z4JLUKQNckjplgEtSpwxwSeqUAS5JnZo1wJN8LsmBJPdPaluX5I4ke9pw7WjLlCRNNcwR+N8Bl0xp2wzsqKrTgR1tWpK0hGYN8Kr6F+BHU5ovB7a18W3AFYtclyRpFqvnud6JVbUfoKr2JzlhpgWTbAI2AZxyyinz/HXLZ8Pm24de9tEtl42wEkk61MgvYlbV1qoar6rxsbGxUf86SXrOmG+AP5FkPUAbHli8kiRJw5hvgN8KbGzjG4Hti1OOJGlYw9xGeAPw78AZSfYluRrYAlycZA9wcZuWJC2hWS9iVtVVM8y6aJFrkSTNgU9iSlKnDHBJ6pQBLkmdmu+DPFoCwz5E5ANE0nOTR+CS1CkDXJI6ZYBLUqcMcEnqlAEuSZ3yLpRFNJevnpWkhfIIXJI6ZYBLUqcMcEnqlAEuSZ0ywCWpUwa4JHXK2wifQ/xyLOno4hG4JHXKAJekTnkKRYfxVIs0nOX+W/EIXJI6ZYBLUqcWdAolySXAJ4BVwHVVtWVRqtKc9PAlWsv1UXM5P+Iu9n4Ztsbl/li/HJ6LfYYFHIEnWQX8LfB64EzgqiRnLlZhkqQjW8gplHOBvVX1SFX9HPgicPnilCVJmk2qan4rJm8CLqmqd7TptwKvqqp3T1luE7CpTZ4BPDTPWo8HnpznuiuFfVgZjoY+wNHRD/swnN+sqrGpjQs5B55p2g7716CqtgJbF/B7Br8s2VVV4wv9OcvJPqwMR0Mf4Ojoh31YmIWcQtkHvGzS9MnA4wsrR5I0rIUE+DeB05OcmuQY4Erg1sUpS5I0m3mfQqmqp5O8G/g6g9sIP1dVDyxaZYdb8GmYFcA+rAxHQx/g6OiHfViAeV/ElCQtL5/ElKROGeCS1KkVH+BJLknyUJK9STYvdz2TJXlZkjuT7E7yQJL3tvZ1Se5IsqcN17b2JPlk68t9Sc6Z9LM2tuX3JNm4DH1ZleSeJLe16VOT7Gz13NguVJPk+W16b5u/YdLPuKa1P5Tk95ehD2uS3JzkwbZPzu9tXyT5k/Zeuj/JDUmOXen7IsnnkhxIcv+ktkXb7kl+O8l32jqfTDLdLcyj6MNH23vpviRfSbJm0rxpt+9MeTXTPlywqlqxLwYXRx8GTgOOAb4NnLncdU2qbz1wTht/MfAfDL5W4CPA5ta+Gbi2jV8KfJXBPfTnATtb+zrgkTZc28bXLnFf3g98AbitTd8EXNnGPw38cRt/J/DpNn4lcGMbP7Ptn+cDp7b9tmqJ+7ANeEcbPwZY09O+AE4Cvge8YNI++KOVvi+AVwPnAPdPalu07Q58Azi/rfNV4PVL1IfXAavb+LWT+jDt9uUIeTXTPlxw3UvxxlzARj0f+Pqk6WuAa5a7riPUux24mMHTputb23rgoTb+GeCqScs/1OZfBXxmUvshyy1B3ScDO4ALgdvaH8qTk968z+wHBncdnd/GV7flMnXfTF5uifrwEgbhlynt3ewLBgH+/RZiq9u++P0e9gWwYUr4Lcp2b/MenNR+yHKj7MOUeX8AXN/Gp92+zJBXR/p7WuhrpZ9COfiGPmhfa1tx2sfXs4GdwIlVtR+gDU9oi83Un+Xu58eBDwC/atMvBZ6qqqenqeeZWtv8/27LL3cfTgMmgM+3U0HXJTmOjvZFVf0A+CvgMWA/g217N/3tC1i87X5SG5/avtTezuDoH+behyP9PS3ISg/woR7XX25JXgR8GXhfVf3kSItO01ZHaB+5JG8ADlTV3ZObj1DPiutDs5rBR+BPVdXZwM8YfHSfyYrrRztPfDmDj+W/ARzH4Ns+Z6pnxfVhCHOtedn7kuRDwNPA9QebpllsWfqw0gN8xT+un+R5DML7+qq6pTU/kWR9m78eONDaZ+rPcvbzAuCNSR5l8I2SFzI4Il+T5OCDXpPreabWNv/XgR+x/PtqH7Cvqna26ZsZBHpP++K1wPeqaqKqfgHcAvwO/e0LWLztvq+NT21fEu1i6huAt1Q7/8Hc+/AkM+/DhRnlebFFOCe1msHFjFN59qLAK5a7rkn1Bfh74ONT2j/KoRdwPtLGL+PQCzjfaO3rGJy/Xdte3wPWLUN/XsOzFzG/xKEXXd7Zxt/FoRfObmrjr+DQCzuPsPQXMf8VOKON/0XbD93sC+BVwAPAC1td24D39LAvOPwc+KJtdwZf23Eez17EvHSJ+nAJ8F1gbMpy025fjpBXM+3DBde8FG/MBW7USxnc3fEw8KHlrmdKbb/L4KPQfcC97XUpg3NeO4A9bXjwjRgG/wnGw8B3gPFJP+vtwN72etsy9ec1PBvgpzG4+r+3vfme39qPbdN72/zTJq3/oda3hxjBnQJD1H8WsKvtj39sQdDVvgA+DDwI3A/8QwuJFb0vgBsYnLP/BYOj0KsXc7sD4217PAz8DVMuVI+wD3sZnNM++Lf96dm2LzPk1Uz7cKEvH6WXpE6t9HPgkqQZGOCS1CkDXJI6ZYBLUqcMcEnqlAEuSZ0ywCWpU/8PZvo1uIsAUKoAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(ff_cbg_data['Fast Food Consumers'], bins=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# We see that the bulk of restaurants fall before 2000, and\n",
    "# that anything in the bucket from 1656 on is in appears to perform in\n",
    "# excess of the average location\n",
    "ff_cbg_data['Successful Location'] =\\\n",
    "    ff_cbg_data['Fast Food Consumers'] >= 1656"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally seperate features and output, to begin remove our potential\n",
    "# output columns, and input.\n",
    "output_variables = ff_cbg_data[[\n",
    "    'Fast Food Count', 'Fast Food Consumers', 'Successful Location']].copy()\n",
    "\n",
    "input_variables = ff_cbg_data.copy()\n",
    "del input_variables['Fast Food Count']\n",
    "del input_variables['Fast Food Consumers']\n",
    "del input_variables['Successful Location']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And then split out testing data for later verification\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    input_variables, output_variables, test_size=0.2,\n",
    "    stratify=output_variables['Successful Location'],\n",
    "    random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And as many machine learning alogorithms perform better with scaled\n",
    "# data we'll prepare a scaled data set\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "df_columns = x_train.columns\n",
    "\n",
    "ss = StandardScaler().fit(x_train)\n",
    "\n",
    "train_data_scaled = ss.transform(x_train)\n",
    "train_data_scaled = pd.DataFrame(train_data_scaled)\n",
    "train_data_scaled.columns = df_columns\n",
    "x_train_scaled = train_data_scaled.copy()\n",
    "\n",
    "test_data_scaled = ss.transform(x_test)\n",
    "test_data_scaled = pd.DataFrame(test_data_scaled)\n",
    "test_data_scaled.columns = df_columns\n",
    "x_test_scaled = test_data_scaled.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression\n",
    "We'll start by treating this as a regression problem on total of fast food traffic, and use cost functions to identify the most important features in predicting count of consumers in an area. Then using those identified variables we'll move on to classification to see what accuracy we can achieve in predicting if an area is a 'successful' one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jon-e-pizza/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([0.00185289, 0.0020792 , 0.00182285, 0.00160866, 0.00157766,\n",
       "        0.00155497, 0.00156608]),\n",
       " 'std_fit_time': array([2.70290448e-04, 7.68751853e-04, 1.17482806e-04, 7.94819604e-05,\n",
       "        2.32764922e-05, 5.49708663e-06, 1.44864353e-05]),\n",
       " 'mean_score_time': array([0.00083146, 0.001089  , 0.00098739, 0.00080481, 0.00081468,\n",
       "        0.00082169, 0.00080647]),\n",
       " 'std_score_time': array([2.81299977e-05, 3.90556751e-04, 1.98825806e-04, 1.26146637e-05,\n",
       "        1.55166357e-05, 4.54955128e-05, 1.14456811e-05]),\n",
       " 'param_alpha': masked_array(data=[0.001, 0.01, 1, 10, 100, 1000, 10000],\n",
       "              mask=[False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'alpha': 0.001},\n",
       "  {'alpha': 0.01},\n",
       "  {'alpha': 1},\n",
       "  {'alpha': 10},\n",
       "  {'alpha': 100},\n",
       "  {'alpha': 1000},\n",
       "  {'alpha': 10000}],\n",
       " 'split0_test_score': array([-0.57093007, -0.57074707, -0.55130664, -0.42021925, -0.07062769,\n",
       "        -0.0357034 , -0.2298275 ]),\n",
       " 'split1_test_score': array([-2.41589225, -2.41308567, -2.15691565, -1.27714385, -0.09219865,\n",
       "         0.02045937, -0.3013425 ]),\n",
       " 'split2_test_score': array([ 0.0475538 ,  0.04760143,  0.05147428,  0.05830321,  0.04628095,\n",
       "        -0.01328329, -0.05326615]),\n",
       " 'split3_test_score': array([-3.1089155 , -3.10035203, -2.49209782, -1.61390393, -1.14333265,\n",
       "        -0.94182503, -1.02076677]),\n",
       " 'split4_test_score': array([ 0.63763357,  0.63744304,  0.61250421,  0.44665861,  0.18585835,\n",
       "        -0.03221657, -0.10072891]),\n",
       " 'mean_test_score': array([-1.093652  , -1.09135337, -0.91746814, -0.5680256 , -0.21749295,\n",
       "        -0.2016433 , -0.34280018]),\n",
       " 'std_test_score': array([1.43886373, 1.43590675, 1.21661324, 0.77798258, 0.47514598,\n",
       "        0.37217735, 0.35177272]),\n",
       " 'rank_test_score': array([7, 6, 5, 4, 2, 1, 3], dtype=int32)}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "ridge = Ridge(max_iter=1000000)\n",
    "parameters = {'alpha': [.001, .01, 1, 10, 100, 1000, 10000]}\n",
    "gcv = GridSearchCV(ridge, parameters, scoring='r2', cv=5)\n",
    "gcv.fit(x_train_scaled, y_train['Fast Food Consumers'])\n",
    "gcv.cv_results_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our scores for different splits are all over the place. We face that even normalized our dataset may not fit a linear model very well, and that we simply don't have enough data to do a 5 split cv. We will try again with a 2 split cross validation and see if our scores are more consistent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jon-e-pizza/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([0.00228143, 0.00178874, 0.00168395, 0.00170565, 0.00172806,\n",
       "        0.00158024, 0.00199103]),\n",
       " 'std_fit_time': array([4.65631485e-04, 1.29938126e-05, 6.91413879e-06, 6.12735748e-05,\n",
       "        1.14679337e-04, 2.45571136e-05, 3.47852707e-04]),\n",
       " 'mean_score_time': array([0.00095797, 0.00093079, 0.00086749, 0.00087285, 0.00085855,\n",
       "        0.00082755, 0.00137174]),\n",
       " 'std_score_time': array([9.36985016e-05, 9.53674316e-06, 4.61339951e-05, 3.64780426e-05,\n",
       "        2.67028809e-05, 2.31266022e-05, 4.11629677e-04]),\n",
       " 'param_alpha': masked_array(data=[0.001, 0.01, 1, 10, 100, 1000, 10000],\n",
       "              mask=[False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'alpha': 0.001},\n",
       "  {'alpha': 0.01},\n",
       "  {'alpha': 1},\n",
       "  {'alpha': 10},\n",
       "  {'alpha': 100},\n",
       "  {'alpha': 1000},\n",
       "  {'alpha': 10000}],\n",
       " 'split0_test_score': array([-0.32892673, -0.32824975, -0.26835534, -0.09632725,  0.10138035,\n",
       "         0.05428803, -0.01786366]),\n",
       " 'split1_test_score': array([ 0.37912781,  0.37960028,  0.38504897,  0.29249602,  0.17292964,\n",
       "         0.03380249, -0.01083795]),\n",
       " 'mean_test_score': array([ 0.02272452,  0.02329993,  0.05615419,  0.09677961,  0.1369149 ,\n",
       "         0.044114  , -0.01437438]),\n",
       " 'std_test_score': array([0.3540193 , 0.35391704, 0.3266948 , 0.19440726, 0.03577384,\n",
       "        0.01024254, 0.00351278]),\n",
       " 'rank_test_score': array([6, 5, 3, 2, 1, 4, 7], dtype=int32)}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge = Ridge(max_iter=1000000)\n",
    "parameters = {'alpha': [.001, .01, 1, 10, 100, 1000, 10000]}\n",
    "gcv = GridSearchCV(ridge, parameters, scoring='r2', cv=2)\n",
    "gcv.fit(x_train_scaled, y_train['Fast Food Consumers'])\n",
    "gcv.cv_results_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our $R^2$s seem to converge a lot better with just two folds. Lets see the coefficients for the best model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Variable</th>\n",
       "      <th>Coefficients</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Total Population</td>\n",
       "      <td>123.193747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Pop. that Works from Home</td>\n",
       "      <td>86.202973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Single Occupant Households</td>\n",
       "      <td>-5.312446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Single Parent Households</td>\n",
       "      <td>-111.949563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Married Parent Households</td>\n",
       "      <td>-35.398090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>Undergrads and Grads</td>\n",
       "      <td>348.164158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>Diploma/GED attained</td>\n",
       "      <td>22.274591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>Degree attained</td>\n",
       "      <td>-60.861319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>Households in Poverty</td>\n",
       "      <td>-59.668802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>Below 40k Earners</td>\n",
       "      <td>1.176450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>40k-100k Earners</td>\n",
       "      <td>-61.008121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>Above 100k Earners</td>\n",
       "      <td>-72.174787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>Unemployed</td>\n",
       "      <td>-8.808321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>Renter Occupied Households</td>\n",
       "      <td>-22.379555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>Owner Occupied Households</td>\n",
       "      <td>-65.031132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>Crime Counts</td>\n",
       "      <td>166.142680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>walk_score</td>\n",
       "      <td>-32.763899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>transit_score</td>\n",
       "      <td>173.105947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>raw_visit_count</td>\n",
       "      <td>520.813782</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Variable  Coefficients\n",
       "0             Total Population    123.193747\n",
       "1    Pop. that Works from Home     86.202973\n",
       "2   Single Occupant Households     -5.312446\n",
       "3     Single Parent Households   -111.949563\n",
       "4    Married Parent Households    -35.398090\n",
       "5         Undergrads and Grads    348.164158\n",
       "6         Diploma/GED attained     22.274591\n",
       "7              Degree attained    -60.861319\n",
       "8        Households in Poverty    -59.668802\n",
       "9            Below 40k Earners      1.176450\n",
       "10            40k-100k Earners    -61.008121\n",
       "11          Above 100k Earners    -72.174787\n",
       "12                  Unemployed     -8.808321\n",
       "13  Renter Occupied Households    -22.379555\n",
       "14   Owner Occupied Households    -65.031132\n",
       "15                Crime Counts    166.142680\n",
       "16                  walk_score    -32.763899\n",
       "17               transit_score    173.105947\n",
       "18             raw_visit_count    520.813782"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({'Variable': x_train_scaled.columns, 'Coefficients': gcv.best_estimator_.coef_})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model clearly emphasizes 'raw_visit_count' and 'Undergrads and Grads'. The following metrics of note are 'transit_score', and 'Crime Counts', and then a little after that 'Total Population' and 'Single Parent Households'. Lets see how linear regression on just there variables fares:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model score on training data: 0.5068456980713572\n",
      "Model score on testing data: 0.5564381747231268\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "x_train_subset = x_train[['Undergrads and Grads', 'raw_visit_count']].copy()\n",
    "x_test_subset = x_test[['Undergrads and Grads', 'raw_visit_count']].copy()\n",
    "lm = LinearRegression()\n",
    "lm.fit(x_train_subset, y_train['Fast Food Consumers'])\n",
    "tr_score = lm.score(x_train_subset, y_train['Fast Food Consumers'])\n",
    "te_score = lm.score(x_test_subset, y_test['Fast Food Consumers'])\n",
    "print('Model score on training data: {}'.format(tr_score))\n",
    "print('Model score on testing data: {}'.format(te_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model score on training data: 0.3464531131041542\n",
      "Model score on testing data: 0.5829130153209574\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "x_train_subset = x_train[[\n",
    "    'Total Population', 'Undergrads and Grads',\n",
    "    'transit_score', 'Crime Counts']].copy()\n",
    "x_test_subset = x_test[[\n",
    "    'Total Population', 'Undergrads and Grads',\n",
    "    'transit_score', 'Crime Counts']].copy()\n",
    "lm = LinearRegression()\n",
    "lm.fit(x_train_subset, y_train['Fast Food Consumers'])\n",
    "tr_score = lm.score(x_train_subset, y_train['Fast Food Consumers'])\n",
    "te_score = lm.score(x_test_subset, y_test['Fast Food Consumers'])\n",
    "print('Model score on training data: {}'.format(tr_score))\n",
    "print('Model score on testing data: {}'.format(te_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model score on training data: 0.3499408952745693\n",
      "Model score on testing data: 0.5817620646400972\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "x_train_subset = x_train[[\n",
    "    'Total Population', 'Undergrads and Grads',\n",
    "    'transit_score', 'Crime Counts', 'Total Population',\n",
    "    'Single Parent Households']].copy()\n",
    "x_test_subset = x_test[[\n",
    "    'Total Population', 'Undergrads and Grads',\n",
    "    'transit_score', 'Crime Counts', 'Total Population',\n",
    "    'Single Parent Households']].copy()\n",
    "lm = LinearRegression()\n",
    "lm.fit(x_train_subset, y_train['Fast Food Consumers'])\n",
    "tr_score = lm.score(x_train_subset, y_train['Fast Food Consumers'])\n",
    "te_score = lm.score(x_test_subset, y_test['Fast Food Consumers'])\n",
    "print('Model score on training data: {}'.format(tr_score))\n",
    "print('Model score on testing data: {}'.format(te_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of the varying levels of influence, it truly does appear a model based on just 'Undergrads and Grads' and 'raw_visit_count' performs best with $R^2$ score over .5 on both training and testing data, while the introduction of the other variables causes the model too fall noticably in performance on the training data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For another datapoint, we try the Lasso cost function to see if the variables it emphasizes performs better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jon-e-pizza/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([1.21149743, 0.1221509 , 0.00327468, 0.00195396, 0.00160086,\n",
       "        0.00157893, 0.00156236]),\n",
       " 'std_fit_time': array([2.95332789e-01, 3.03814411e-02, 3.89575958e-04, 1.33156776e-04,\n",
       "        7.74860382e-06, 2.49147415e-05, 1.43051147e-06]),\n",
       " 'mean_score_time': array([0.00108898, 0.00084114, 0.00082064, 0.0008086 , 0.00081873,\n",
       "        0.00079632, 0.00079596]),\n",
       " 'std_score_time': array([7.74860382e-06, 1.85966492e-05, 1.04904175e-05, 1.01327896e-05,\n",
       "        2.38418579e-06, 1.43051147e-06, 3.57627869e-07]),\n",
       " 'param_alpha': masked_array(data=[0.001, 0.01, 1, 10, 100, 1000, 10000],\n",
       "              mask=[False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'alpha': 0.001},\n",
       "  {'alpha': 0.01},\n",
       "  {'alpha': 1},\n",
       "  {'alpha': 10},\n",
       "  {'alpha': 100},\n",
       "  {'alpha': 1000},\n",
       "  {'alpha': 10000}],\n",
       " 'split0_test_score': array([-0.32899292, -0.32891006, -0.31961928, -0.24101115, -0.01700314,\n",
       "         0.04958837, -0.03013447]),\n",
       " 'split1_test_score': array([ 0.3790775 ,  0.37910657,  0.38447045,  0.42069581,  0.17814244,\n",
       "        -0.01749851, -0.01749851]),\n",
       " 'mean_test_score': array([ 0.02266621,  0.02272236,  0.03006287,  0.08762184,  0.0799148 ,\n",
       "         0.01627005, -0.02385889]),\n",
       " 'std_test_score': array([0.35402724, 0.35400034, 0.35203694, 0.33084603, 0.09757059,\n",
       "        0.03354268, 0.00631784]),\n",
       " 'rank_test_score': array([5, 4, 3, 1, 2, 6, 7], dtype=int32)}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "lasso = Lasso(max_iter=1000000)\n",
    "parameters = {'alpha': [.001, .01, 1, 10, 100, 1000, 10000]}\n",
    "gcv = GridSearchCV(lasso, parameters, scoring='r2', cv=2)\n",
    "gcv.fit(x_train_scaled, y_train['Fast Food Consumers'])\n",
    "gcv.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Variable</th>\n",
       "      <th>Coefficients</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Total Population</td>\n",
       "      <td>-175.791793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Pop. that Works from Home</td>\n",
       "      <td>39.385199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Single Occupant Households</td>\n",
       "      <td>-54.996133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Single Parent Households</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Married Parent Households</td>\n",
       "      <td>6.218625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>Undergrads and Grads</td>\n",
       "      <td>735.429668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>Diploma/GED attained</td>\n",
       "      <td>96.407597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>Degree attained</td>\n",
       "      <td>-57.130900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>Households in Poverty</td>\n",
       "      <td>-0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>Below 40k Earners</td>\n",
       "      <td>43.315443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>40k-100k Earners</td>\n",
       "      <td>-0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>Above 100k Earners</td>\n",
       "      <td>-131.183178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>Unemployed</td>\n",
       "      <td>-5.220467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>Renter Occupied Households</td>\n",
       "      <td>-19.226498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>Owner Occupied Households</td>\n",
       "      <td>48.277521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>Crime Counts</td>\n",
       "      <td>-205.478070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>walk_score</td>\n",
       "      <td>-125.304655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>transit_score</td>\n",
       "      <td>315.515481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>raw_visit_count</td>\n",
       "      <td>1163.815236</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Variable  Coefficients\n",
       "0             Total Population   -175.791793\n",
       "1    Pop. that Works from Home     39.385199\n",
       "2   Single Occupant Households    -54.996133\n",
       "3     Single Parent Households      0.000000\n",
       "4    Married Parent Households      6.218625\n",
       "5         Undergrads and Grads    735.429668\n",
       "6         Diploma/GED attained     96.407597\n",
       "7              Degree attained    -57.130900\n",
       "8        Households in Poverty     -0.000000\n",
       "9            Below 40k Earners     43.315443\n",
       "10            40k-100k Earners     -0.000000\n",
       "11          Above 100k Earners   -131.183178\n",
       "12                  Unemployed     -5.220467\n",
       "13  Renter Occupied Households    -19.226498\n",
       "14   Owner Occupied Households     48.277521\n",
       "15                Crime Counts   -205.478070\n",
       "16                  walk_score   -125.304655\n",
       "17               transit_score    315.515481\n",
       "18             raw_visit_count   1163.815236"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({'Variable': x_train_scaled.columns, 'Coefficients': gcv.best_estimator_.coef_})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model again suggests that 'Undergrads and Grads' and 'raw_visit_count' are the most important features, and also supports 'transit_score' as important, but Lasso seems to emphasize 'Diploma/GED attained' and 'Above 100k Earners' where Ridge did not. We'll see how a model on these variables fits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model score on training data: 0.5449707241830134\n",
      "Model score on testing data: 0.5661148734273115\n"
     ]
    }
   ],
   "source": [
    "x_train_subset = x_train[[\n",
    "    'Total Population', 'Undergrads and Grads',\n",
    "    'Diploma/GED attained', 'Above 100k Earners', 'Crime Counts',\n",
    "    'walk_score', 'transit_score', 'raw_visit_count']].copy()\n",
    "x_test_subset = x_test[[\n",
    "    'Total Population', 'Undergrads and Grads',\n",
    "    'Diploma/GED attained', 'Above 100k Earners', 'Crime Counts',\n",
    "    'walk_score', 'transit_score', 'raw_visit_count']].copy()\n",
    "lm = LinearRegression()\n",
    "lm.fit(x_train_subset, y_train['Fast Food Consumers'])\n",
    "tr_score = lm.score(x_train_subset, y_train['Fast Food Consumers'])\n",
    "te_score = lm.score(x_test_subset, y_test['Fast Food Consumers'])\n",
    "print('Model score on training data: {}'.format(tr_score))\n",
    "print('Model score on testing data: {}'.format(te_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And this model actually seems to generalize best of our linear models, so this might be our best set of features. But just for one last input with the linear model, we use RFE to rank our features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Variable</th>\n",
       "      <th>Ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Total Population</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Pop. that Works from Home</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Single Occupant Households</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Single Parent Households</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Married Parent Households</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>Undergrads and Grads</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>Diploma/GED attained</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>Degree attained</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>Households in Poverty</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>Below 40k Earners</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>40k-100k Earners</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>Above 100k Earners</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>Unemployed</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>Renter Occupied Households</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>Owner Occupied Households</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>Crime Counts</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>walk_score</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>transit_score</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>raw_visit_count</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Variable  Ranking\n",
       "0             Total Population        3\n",
       "1    Pop. that Works from Home       11\n",
       "2   Single Occupant Households        5\n",
       "3     Single Parent Households       12\n",
       "4    Married Parent Households       13\n",
       "5         Undergrads and Grads        1\n",
       "6         Diploma/GED attained        8\n",
       "7              Degree attained       18\n",
       "8        Households in Poverty       14\n",
       "9            Below 40k Earners        4\n",
       "10            40k-100k Earners        6\n",
       "11          Above 100k Earners       15\n",
       "12                  Unemployed       16\n",
       "13  Renter Occupied Households       17\n",
       "14   Owner Occupied Households       10\n",
       "15                Crime Counts        2\n",
       "16                  walk_score        9\n",
       "17               transit_score        7\n",
       "18             raw_visit_count        1"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lm = LinearRegression()\n",
    "\n",
    "rfe = RFECV(lm, cv=2)\n",
    "rfe.fit(x_train_scaled, y_train['Fast Food Consumers'])\n",
    "pd.DataFrame({'Variable': x_train_scaled.columns, 'Ranking': rfe.ranking_})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But this method doesn't reveal more than just 'raw_visit_count' and 'Undergrads and Grads' stand above all other features in prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before switching to approach this as a classification problem, we first turn to decision tree regressors to see if we can produce a better fitting model if we abandon our linear constraints. Note we don't have to use our scaled dataset with our tree model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model score on training data: 0.8923444516415268\n",
      "Model score on testing data: 0.6063601876394138\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Variable</th>\n",
       "      <th>Coefficient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Total Population</td>\n",
       "      <td>0.050074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Pop. that Works from Home</td>\n",
       "      <td>0.018094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Single Occupant Households</td>\n",
       "      <td>0.018734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Single Parent Households</td>\n",
       "      <td>0.009956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Married Parent Households</td>\n",
       "      <td>0.009811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>Undergrads and Grads</td>\n",
       "      <td>0.305185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>Diploma/GED attained</td>\n",
       "      <td>0.019438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>Degree attained</td>\n",
       "      <td>0.046312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>Households in Poverty</td>\n",
       "      <td>0.073707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>Below 40k Earners</td>\n",
       "      <td>0.068694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>40k-100k Earners</td>\n",
       "      <td>0.024868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>Above 100k Earners</td>\n",
       "      <td>0.011498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>Unemployed</td>\n",
       "      <td>0.011428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>Renter Occupied Households</td>\n",
       "      <td>0.014320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>Owner Occupied Households</td>\n",
       "      <td>0.039284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>Crime Counts</td>\n",
       "      <td>0.074551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>walk_score</td>\n",
       "      <td>0.071843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>transit_score</td>\n",
       "      <td>0.007920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>raw_visit_count</td>\n",
       "      <td>0.124284</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Variable  Coefficient\n",
       "0             Total Population     0.050074\n",
       "1    Pop. that Works from Home     0.018094\n",
       "2   Single Occupant Households     0.018734\n",
       "3     Single Parent Households     0.009956\n",
       "4    Married Parent Households     0.009811\n",
       "5         Undergrads and Grads     0.305185\n",
       "6         Diploma/GED attained     0.019438\n",
       "7              Degree attained     0.046312\n",
       "8        Households in Poverty     0.073707\n",
       "9            Below 40k Earners     0.068694\n",
       "10            40k-100k Earners     0.024868\n",
       "11          Above 100k Earners     0.011498\n",
       "12                  Unemployed     0.011428\n",
       "13  Renter Occupied Households     0.014320\n",
       "14   Owner Occupied Households     0.039284\n",
       "15                Crime Counts     0.074551\n",
       "16                  walk_score     0.071843\n",
       "17               transit_score     0.007920\n",
       "18             raw_visit_count     0.124284"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "forest = RandomForestRegressor(n_estimators=350, random_state=42)\n",
    "forest.fit(x_train, y_train['Fast Food Consumers'])\n",
    "tr_score = forest.score(x_train, y_train['Fast Food Consumers'])\n",
    "te_score = forest.score(x_test, y_test['Fast Food Consumers'])\n",
    "print('Model score on training data: {}'.format(tr_score))\n",
    "print('Model score on testing data: {}'.format(te_score))\n",
    "pd.DataFrame({'Variable': x_train.columns, 'Coefficient': forest.feature_importances_})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And perhaps as expected our tree based model scores better than our linear model on both training and test data. Additionally, our regressor continues to emphasize 'Undergrads and Grads' and 'raw_visit_count', and 'Crime Counts' is again seen as a runner up, but then this model is the first to point to the predictive power of 'Households in Poverty', and 'Below 40k Earners'. We will take note of this when sampling variables for our classifiers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before turning to our classifiers though, we see if a GradientBoosting algorithm on our trees can increase our prediction power."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model score on training data: 0.8161663182048728\n",
      "Model score on testing data: 0.5897843086228176\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Variable</th>\n",
       "      <th>Feature Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Total Population</td>\n",
       "      <td>0.018210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Pop. that Works from Home</td>\n",
       "      <td>0.013704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Single Occupant Households</td>\n",
       "      <td>0.008220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Single Parent Households</td>\n",
       "      <td>0.001857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Married Parent Households</td>\n",
       "      <td>0.003450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>Undergrads and Grads</td>\n",
       "      <td>0.472460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>Diploma/GED attained</td>\n",
       "      <td>0.039818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>Degree attained</td>\n",
       "      <td>0.099454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>Households in Poverty</td>\n",
       "      <td>0.027791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>Below 40k Earners</td>\n",
       "      <td>0.004061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>40k-100k Earners</td>\n",
       "      <td>0.001577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>Above 100k Earners</td>\n",
       "      <td>0.004524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>Unemployed</td>\n",
       "      <td>0.001325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>Renter Occupied Households</td>\n",
       "      <td>0.008543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>Owner Occupied Households</td>\n",
       "      <td>0.002149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>Crime Counts</td>\n",
       "      <td>0.068280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>walk_score</td>\n",
       "      <td>0.174245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>transit_score</td>\n",
       "      <td>0.006017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>raw_visit_count</td>\n",
       "      <td>0.044313</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Variable  Feature Importance\n",
       "0             Total Population            0.018210\n",
       "1    Pop. that Works from Home            0.013704\n",
       "2   Single Occupant Households            0.008220\n",
       "3     Single Parent Households            0.001857\n",
       "4    Married Parent Households            0.003450\n",
       "5         Undergrads and Grads            0.472460\n",
       "6         Diploma/GED attained            0.039818\n",
       "7              Degree attained            0.099454\n",
       "8        Households in Poverty            0.027791\n",
       "9            Below 40k Earners            0.004061\n",
       "10            40k-100k Earners            0.001577\n",
       "11          Above 100k Earners            0.004524\n",
       "12                  Unemployed            0.001325\n",
       "13  Renter Occupied Households            0.008543\n",
       "14   Owner Occupied Households            0.002149\n",
       "15                Crime Counts            0.068280\n",
       "16                  walk_score            0.174245\n",
       "17               transit_score            0.006017\n",
       "18             raw_visit_count            0.044313"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "gbr = GradientBoostingRegressor(n_estimators = 100, max_depth=5, learning_rate=.01, random_state=42)\n",
    "gbr.fit(x_train, y_train['Fast Food Consumers'])\n",
    "\n",
    "tr_score = gbr.score(x_train, y_train['Fast Food Consumers'])\n",
    "te_score = gbr.score(x_test, y_test['Fast Food Consumers'])\n",
    "print('Model score on training data: {}'.format(tr_score))\n",
    "print('Model score on testing data: {}'.format(te_score))\n",
    "\n",
    "pd.DataFrame({'Variable': x_train.columns, 'Feature Importance': gbr.feature_importances_})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We don't see any increase in predictive power, but we do see 'Degree attained' as a surprisingly important feature for prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since our random forest regressor seemed to be the best fit for predicting consumership, and our goal is to predict where we should open restaurants, we also want to have a model to know where there are fewer establishments than could be predicted. To predict this count of restaurants we probably want to actually use the fast food consumers as a predictor, so we'll add that to our previous best performing Random Forest model with the variables that were emphasized there:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model score on training data: 0.9423576879469737\n",
      "Model score on testing data: 0.05862344704305067\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Variable</th>\n",
       "      <th>Coefficient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Total Population</td>\n",
       "      <td>0.031844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Undergrads and Grads</td>\n",
       "      <td>0.052583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Degree attained</td>\n",
       "      <td>0.027531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Households in Poverty</td>\n",
       "      <td>0.063509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Below 40k Earners</td>\n",
       "      <td>0.051631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>Crime Counts</td>\n",
       "      <td>0.134555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>walk_score</td>\n",
       "      <td>0.028563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>raw_visit_count</td>\n",
       "      <td>0.066670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>Fast Food Consumers</td>\n",
       "      <td>0.543114</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Variable  Coefficient\n",
       "0       Total Population     0.031844\n",
       "1   Undergrads and Grads     0.052583\n",
       "2        Degree attained     0.027531\n",
       "3  Households in Poverty     0.063509\n",
       "4      Below 40k Earners     0.051631\n",
       "5           Crime Counts     0.134555\n",
       "6             walk_score     0.028563\n",
       "7        raw_visit_count     0.066670\n",
       "8    Fast Food Consumers     0.543114"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_count = x_train[['Total Population', 'Undergrads and Grads', \n",
    "    'Degree attained', 'Households in Poverty', 'Below 40k Earners',\n",
    "    'Crime Counts', 'walk_score', 'raw_visit_count']].copy()\n",
    "x_train_count['Fast Food Consumers'] = y_train['Fast Food Consumers']\n",
    "\n",
    "x_test_count = x_test[['Total Population', 'Undergrads and Grads',\n",
    "    'Degree attained', 'Households in Poverty', 'Below 40k Earners',\n",
    "    'Crime Counts', 'walk_score', 'raw_visit_count']].copy()\n",
    "x_test_count['Fast Food Consumers'] = y_test['Fast Food Consumers']\n",
    "\n",
    "forest = RandomForestRegressor(n_estimators=350, random_state=42)\n",
    "forest.fit(x_train_count, y_train['Fast Food Count'])\n",
    "tr_score = forest.score(x_train_count, y_train['Fast Food Count'])\n",
    "te_score = forest.score(x_test_count, y_test['Fast Food Count'])\n",
    "print('Model score on training data: {}'.format(tr_score))\n",
    "print('Model score on testing data: {}'.format(te_score))\n",
    "pd.DataFrame({'Variable': x_train_count.columns, 'Coefficient': forest.feature_importances_})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The very different $R^2$ scores between training and testing data for this regressor may indicate it generalizes too poorly to be a useful model, but if we can trust it we would like to determine where the current establishment count is lower than predicted as places where we might want to make a new location:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fast Food Count</th>\n",
       "      <th>Predicted Count</th>\n",
       "      <th>Successful Location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>421010004011</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>421010312002</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Fast Food Count  Predicted Count  Successful Location\n",
       "421010004011                3                4                 True\n",
       "421010312002                1                2                 True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pc = pd.DataFrame({\n",
    "    'Fast Food Count': y_train['Fast Food Count'].astype(int),\n",
    "    'Predicted Count': forest.predict(x_train_count).astype(int),\n",
    "    'Successful Location': y_train['Successful Location']})\n",
    "pc[pc['Successful Location'] & (pc['Fast Food Count']<pc['Predicted Count'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fast Food Count</th>\n",
       "      <th>Predicted Count</th>\n",
       "      <th>Successful Location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>421010377001</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>421010379003</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>421010146001</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>421010369003</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>421010010011</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Fast Food Count  Predicted Count  Successful Location\n",
       "421010377001                2                4                 True\n",
       "421010379003                4                5                 True\n",
       "421010146001                3                4                 True\n",
       "421010369003                4                5                 True\n",
       "421010010011                2                4                 True"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pc = pd.DataFrame({\n",
    "    'Fast Food Count': y_test['Fast Food Count'].astype(int),\n",
    "    'Predicted Count': forest.predict(x_test_count).astype(int),\n",
    "    'Successful Location': y_test['Successful Location']})\n",
    "pc[pc['Successful Location'] & (pc['Fast Food Count']<pc['Predicted Count'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And our model points us to two locations where we might want to start a new fast food establishment, though again we might take this with a grain of salt due to low score on testing data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification\n",
    "\n",
    "Now we'll start seeing how our classification algorithms perform with our discovered top subsets of features. We'll start with seeing how well we can predict success with linear models (logistic regression, SVM) as before, then see how a perceptron based classifier performs, then move again on to tree models, then kNearest Neighbors, and finally see what a naive bayes predictor can produce.\n",
    "\n",
    "We'll use our best linear model variables from lasso for our linear classifiers. For each classifier we'll output the recall (how many of the successful locations we identified), the precision (how many of the successful locations we predicted were actually confirmed as such), and the Area under the receiver operator curve (relative tradeoff of true positives to false positives)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This classifier has a recall score of 0.32, a precision score of 0.8, and an area under receiver operating curve score of 0.85 on the training data.\n",
      "This classifier has a recall score of 0.5, a precision score of 1.0, and an area under receiver operating curve score of 0.71 on the test data.\n"
     ]
    }
   ],
   "source": [
    "# first we aim to use a logistic regression model. As our best scoring\n",
    "# linear model was produced by our Lasso Cost function, we'll use those\n",
    "# variables in particular for our linear logisitic regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "x_train_subset = x_train_scaled[[\n",
    "    'Total Population', 'Undergrads and Grads',\n",
    "    'Diploma/GED attained', 'Above 100k Earners', 'Crime Counts',\n",
    "    'walk_score', 'transit_score', 'raw_visit_count']].copy()\n",
    "x_test_subset = x_test_scaled[[\n",
    "    'Total Population', 'Undergrads and Grads',\n",
    "    'Diploma/GED attained', 'Above 100k Earners', 'Crime Counts',\n",
    "    'walk_score', 'transit_score', 'raw_visit_count']].copy()\n",
    "\n",
    "logreg = LogisticRegression(solver='lbfgs')\n",
    "logreg.fit(x_train_subset, y_train['Successful Location'])\n",
    "\n",
    "print('This classifier has a recall score of {}'.format(\n",
    "      recall_score(y_train['Successful Location'], logreg.predict(x_train_subset))) +\n",
    "      ', a precision score of {}'.format(\n",
    "      precision_score(y_train['Successful Location'], logreg.predict(x_train_subset))) +\n",
    "      ', and an area under receiver operating curve score of {:.2f}'.format(\n",
    "      roc_auc_score(y_train['Successful Location'], logreg.predict_proba(x_train_subset)[:,1])) +\n",
    "      ' on the training data.')\n",
    "print('This classifier has a recall score of {}'.format(\n",
    "      recall_score(y_test['Successful Location'], logreg.predict(x_test_subset))) +\n",
    "      ', a precision score of {}'.format(\n",
    "      precision_score(y_test['Successful Location'], logreg.predict(x_test_subset))) +\n",
    "      ', and an area under receiver operating curve score of {:.2f}'.format(\n",
    "      roc_auc_score(y_test['Successful Location'], logreg.predict_proba(x_test_subset)[:,1])) +\n",
    "      ' on the test data.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Despite less than stellar performance on the training data, it is good to see a precision of 1 on our test data predictions, and our AUC score does indicate a fairly good classifier (especially on the training data)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we'll see if we can predict better with a SVM and a RBF kernel to try to predict with higher order variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This classifier has a recall score of 0.32, a precision score of 1.0, and an area under receiver operating curve score of 0.93 on the training data.\n",
      "This classifier has a recall score of 0.5, a precision score of 1.0, and an area under receiver operating curve score of 0.87 on the test data.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svm = SVC(kernel='rbf', probability=True)\n",
    "parameters = ({'C': [0.1, 1, 10, 100], 'gamma':  [0.1, 1, 10, 100]})\n",
    "\n",
    "gcv = GridSearchCV(svm, parameters, cv=2, iid=True)\n",
    "gcv.fit(x_train_subset, y_train['Successful Location'])\n",
    "\n",
    "y_train_pred = gcv.best_estimator_.predict(x_train_subset)\n",
    "y_train_ppred = gcv.best_estimator_.predict_proba(x_train_subset)\n",
    "y_test_pred = gcv.best_estimator_.predict(x_test_subset)\n",
    "y_test_ppred = gcv.best_estimator_.predict_proba(x_test_subset)\n",
    "print('This classifier has a recall score of {}'.format(\n",
    "      recall_score(y_train['Successful Location'], y_train_pred)) +\n",
    "      ', a precision score of {}'.format(\n",
    "      precision_score(y_train['Successful Location'], y_train_pred)) +\n",
    "      ', and an area under receiver operating curve score of {:.2f}'.format(\n",
    "      roc_auc_score(y_train['Successful Location'], y_train_ppred[:,1])) +\n",
    "      ' on the training data.')\n",
    "print('This classifier has a recall score of {}'.format(\n",
    "      recall_score(y_test['Successful Location'], y_test_pred)) +\n",
    "      ', a precision score of {}'.format(\n",
    "      precision_score(y_test['Successful Location'], y_test_pred)) +\n",
    "      ', and an area under receiver operating curve score of {:.2f}'.format(\n",
    "      roc_auc_score(y_test['Successful Location'], y_test_ppred[:,1])) +\n",
    "      ' on the test data.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the SVM model the recall and precision don't change much from our logistic regression, the roc auc on the predicted probabilities however indicates a more confident model in predicting successful areas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll now switch from linear models to reduce the bias of our estimators, perhaps at the cost of increased variance in our predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll first feed our full set of variables into a perceptron based learning model and see how well this model predicts our success class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This classifier has a recall score of 1.0, a precision score of 1.0, and an area under receiver operating curve score of 1.00 on the training data.\n",
      "This classifier has a recall score of 0.5, a precision score of 1.0, and an area under receiver operating curve score of 0.77 on the test data.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "mlp = MLPClassifier(max_iter=10000, random_state=42, hidden_layer_sizes=[100,100])\n",
    "mlp.fit(x_train_scaled, y_train['Successful Location'])\n",
    "mlp.score(x_train_scaled, y_train['Successful Location'])\n",
    "\n",
    "print('This classifier has a recall score of {}'.format(\n",
    "      recall_score(y_train['Successful Location'], mlp.predict(x_train_scaled))) +\n",
    "      ', a precision score of {}'.format(\n",
    "      precision_score(y_train['Successful Location'], mlp.predict(x_train_scaled))) +\n",
    "      ', and an area under receiver operating curve score of {:.2f}'.format(\n",
    "      roc_auc_score(y_train['Successful Location'], mlp.predict_proba(x_train_scaled)[:,1])) +\n",
    "      ' on the training data.')\n",
    "print('This classifier has a recall score of {}'.format(\n",
    "      recall_score(y_test['Successful Location'], mlp.predict(x_test_scaled))) +\n",
    "      ', a precision score of {}'.format(\n",
    "      precision_score(y_test['Successful Location'], mlp.predict(x_test_scaled))) +\n",
    "      ', and an area under receiver operating curve score of {:.2f}'.format(\n",
    "      roc_auc_score(y_test['Successful Location'], mlp.predict_proba(x_test_scaled)[:,1])) +\n",
    "      ' on the test data.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And just for a point of comparison we try training with just our Lasso selected variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This classifier has a recall score of 1.0, a precision score of 1.0, and an area under receiver operating curve score of 1.00 on the training data.\n",
      "This classifier has a recall score of 0.6666666666666666, a precision score of 1.0, and an area under receiver operating curve score of 0.86 on the test data.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "mlp = MLPClassifier(max_iter=10000, random_state=42, hidden_layer_sizes=[100,100])\n",
    "mlp.fit(x_train_subset, y_train['Successful Location'])\n",
    "\n",
    "print('This classifier has a recall score of {}'.format(\n",
    "      recall_score(y_train['Successful Location'], mlp.predict(x_train_subset))) +\n",
    "      ', a precision score of {}'.format(\n",
    "      precision_score(y_train['Successful Location'], mlp.predict(x_train_subset))) +\n",
    "      ', and an area under receiver operating curve score of {:.2f}'.format(\n",
    "      roc_auc_score(y_train['Successful Location'], mlp.predict_proba(x_train_subset)[:,1])) +\n",
    "      ' on the training data.')\n",
    "print('This classifier has a recall score of {}'.format(\n",
    "      recall_score(y_test['Successful Location'], mlp.predict(x_test_subset))) +\n",
    "      ', a precision score of {}'.format(\n",
    "      precision_score(y_test['Successful Location'], mlp.predict(x_test_subset))) +\n",
    "      ', and an area under receiver operating curve score of {:.2f}'.format(\n",
    "      roc_auc_score(y_test['Successful Location'], mlp.predict_proba(x_test_subset)[:,1])) +\n",
    "      ' on the test data.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both our perceptron based methods have better recall than our previous linear models on the training data, while the one with our subset of variables also increases recall on the testing data, as well as resulting in a better roc auc score. Both have a the difference in recall and auc between training data and test data that may indicate overfitting though. Lets see if we can produce another model that appears to generalize better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the tree based classifiers with the full data set. We'll first try the RandomForestClassifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This classifier has a recall score of 1.0, a precision score of 1.0, and an area under receiver operating curve score of 1.00 on the training data.\n",
      "This classifier has a recall score of 0.5, a precision score of 0.6, and an area under receiver operating curve score of 0.90 on the test data.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rfc = RandomForestClassifier(n_estimators = 350, random_state=42)\n",
    "rfc.fit(x_train, y_train['Successful Location'])\n",
    "\n",
    "print('This classifier has a recall score of {}'.format(\n",
    "      recall_score(y_train['Successful Location'], rfc.predict(x_train))) +\n",
    "      ', a precision score of {}'.format(\n",
    "      precision_score(y_train['Successful Location'], rfc.predict(x_train))) +\n",
    "      ', and an area under receiver operating curve score of {:.2f}'.format(\n",
    "      roc_auc_score(y_train['Successful Location'], rfc.predict_proba(x_train)[:,1])) +\n",
    "      ' on the training data.')\n",
    "print('This classifier has a recall score of {}'.format(\n",
    "      recall_score(y_test['Successful Location'], rfc.predict(x_test))) +\n",
    "      ', a precision score of {}'.format(\n",
    "      precision_score(y_test['Successful Location'], rfc.predict(x_test))) +\n",
    "      ', and an area under receiver operating curve score of {:.2f}'.format(\n",
    "      roc_auc_score(y_test['Successful Location'], rfc.predict_proba(x_test)[:,1])) +\n",
    "      ' on the test data.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But we see we lose precision on our test data set while precision may be the most important metric to us, even as we do achieve a rather high auc score on the test data. We want to know any predicted successful location is in fact in that class, even if we might miss predicting some. We'll try again with the subset of Lasso variables as we did with MLP, though we can continue to not use the scaled variables with this tree classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This classifier has a recall score of 1.0, a precision score of 1.0, and an area under receiver operating curve score of 1.00 on the training data.\n",
      "This classifier has a recall score of 0.5, a precision score of 1.0, and an area under receiver operating curve score of 0.92 on the test data.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "x_train_subset = x_train[[\n",
    "    'Total Population', 'Undergrads and Grads',\n",
    "    'Diploma/GED attained', 'Above 100k Earners', 'Crime Counts',\n",
    "    'walk_score', 'transit_score', 'raw_visit_count']].copy()\n",
    "x_test_subset = x_test[[\n",
    "    'Total Population', 'Undergrads and Grads',\n",
    "    'Diploma/GED attained', 'Above 100k Earners', 'Crime Counts',\n",
    "    'walk_score', 'transit_score', 'raw_visit_count']].copy()\n",
    "\n",
    "rfc = RandomForestClassifier(n_estimators = 350, random_state=42)\n",
    "rfc.fit(x_train_subset, y_train['Successful Location'])\n",
    "\n",
    "print('This classifier has a recall score of {}'.format(\n",
    "      recall_score(y_train['Successful Location'], rfc.predict(x_train_subset))) +\n",
    "      ', a precision score of {}'.format(\n",
    "      precision_score(y_train['Successful Location'], rfc.predict(x_train_subset))) +\n",
    "      ', and an area under receiver operating curve score of {:.2f}'.format(\n",
    "      roc_auc_score(y_train['Successful Location'], rfc.predict_proba(x_train_subset)[:,1])) +\n",
    "      ' on the training data.')\n",
    "print('This classifier has a recall score of {}'.format(\n",
    "      recall_score(y_test['Successful Location'], rfc.predict(x_test_subset))) +\n",
    "      ', a precision score of {}'.format(\n",
    "      precision_score(y_test['Successful Location'], rfc.predict(x_test_subset))) +\n",
    "      ', and an area under receiver operating curve score of {:.2f}'.format(\n",
    "      roc_auc_score(y_test['Successful Location'], rfc.predict_proba(x_test_subset)[:,1])) +\n",
    "      ' on the test data.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And though we don't have the recall score of our MLP model, we do have our desired precision, and a auc curve indicating a truly superior model.\n",
    "\n",
    "Next we try the gradient boosting classifier with the full variable set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This classifier has a recall score of 1.0, a precision score of 1.0, and an area under receiver operating curve score of 1.00 on the training data.\n",
      "This classifier has a recall score of 0.5, a precision score of 1.0, and an area under receiver operating curve score of 0.91 on the test data.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "gbc = GradientBoostingClassifier(n_estimators = 100, max_depth=5, learning_rate=.1, random_state=42)\n",
    "gbc.fit(x_train, y_train['Successful Location'])\n",
    "\n",
    "print('This classifier has a recall score of {}'.format(\n",
    "      recall_score(y_train['Successful Location'], gbc.predict(x_train))) +\n",
    "      ', a precision score of {}'.format(\n",
    "      precision_score(y_train['Successful Location'], gbc.predict(x_train))) +\n",
    "      ', and an area under receiver operating curve score of {:.2f}'.format(\n",
    "      roc_auc_score(y_train['Successful Location'], gbc.predict_proba(x_train)[:,1])) +\n",
    "      ' on the training data.')\n",
    "print('This classifier has a recall score of {}'.format(\n",
    "      recall_score(y_test['Successful Location'], gbc.predict(x_test))) +\n",
    "      ', a precision score of {}'.format(\n",
    "      precision_score(y_test['Successful Location'], gbc.predict(x_test))) +\n",
    "      ', and an area under receiver operating curve score of {:.2f}'.format(\n",
    "      roc_auc_score(y_test['Successful Location'], gbc.predict_proba(x_test)[:,1])) +\n",
    "      ' on the test data.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We already do as well as the Random Forest with the subset of variables. Lets see what this model predicted for the most important variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Variable</th>\n",
       "      <th>Feature Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Total Population</td>\n",
       "      <td>0.016339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Pop. that Works from Home</td>\n",
       "      <td>0.005981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Single Occupant Households</td>\n",
       "      <td>0.010277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Single Parent Households</td>\n",
       "      <td>0.070895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Married Parent Households</td>\n",
       "      <td>0.065954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>Undergrads and Grads</td>\n",
       "      <td>0.303830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>Diploma/GED attained</td>\n",
       "      <td>0.034028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>Degree attained</td>\n",
       "      <td>0.052723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>Households in Poverty</td>\n",
       "      <td>0.002279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>Below 40k Earners</td>\n",
       "      <td>0.001621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>40k-100k Earners</td>\n",
       "      <td>0.006370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>Above 100k Earners</td>\n",
       "      <td>0.014068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>Unemployed</td>\n",
       "      <td>0.054714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>Renter Occupied Households</td>\n",
       "      <td>0.005590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>Owner Occupied Households</td>\n",
       "      <td>0.004997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>Crime Counts</td>\n",
       "      <td>0.099952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>walk_score</td>\n",
       "      <td>0.090359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>transit_score</td>\n",
       "      <td>0.037400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>raw_visit_count</td>\n",
       "      <td>0.122622</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Variable  Feature Importance\n",
       "0             Total Population            0.016339\n",
       "1    Pop. that Works from Home            0.005981\n",
       "2   Single Occupant Households            0.010277\n",
       "3     Single Parent Households            0.070895\n",
       "4    Married Parent Households            0.065954\n",
       "5         Undergrads and Grads            0.303830\n",
       "6         Diploma/GED attained            0.034028\n",
       "7              Degree attained            0.052723\n",
       "8        Households in Poverty            0.002279\n",
       "9            Below 40k Earners            0.001621\n",
       "10            40k-100k Earners            0.006370\n",
       "11          Above 100k Earners            0.014068\n",
       "12                  Unemployed            0.054714\n",
       "13  Renter Occupied Households            0.005590\n",
       "14   Owner Occupied Households            0.004997\n",
       "15                Crime Counts            0.099952\n",
       "16                  walk_score            0.090359\n",
       "17               transit_score            0.037400\n",
       "18             raw_visit_count            0.122622"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({'Variable': x_train.columns, 'Feature Importance': gbc.feature_importances_})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see the features that are emphasized here are:\n",
    "<li>Undergrads and Grads</li>\n",
    "<li>raw_visit_count</li>\n",
    "<li>Crime Counts</li>\n",
    "<li>walk_score</li>\n",
    "<li>Single Parent Households</li>\n",
    "<li>Married Parent Households</li>\n",
    "\n",
    "We can also try our previous subset as input again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This classifier has a recall score of 1.0, a precision score of 1.0, and an area under receiver operating curve score of 1.00 on the training data.\n",
      "This classifier has a recall score of 0.5, a precision score of 1.0, and an area under receiver operating curve score of 0.91 on the test data.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "gbc = GradientBoostingClassifier(n_estimators = 100, max_depth=5, learning_rate=.1, random_state=42)\n",
    "gbc.fit(x_train_subset, y_train['Successful Location'])\n",
    "\n",
    "print('This classifier has a recall score of {}'.format(\n",
    "      recall_score(y_train['Successful Location'], gbc.predict(x_train_subset))) +\n",
    "      ', a precision score of {}'.format(\n",
    "      precision_score(y_train['Successful Location'], gbc.predict(x_train_subset))) +\n",
    "      ', and an area under receiver operating curve score of {:.2f}'.format(\n",
    "      roc_auc_score(y_train['Successful Location'], gbc.predict_proba(x_train_subset)[:,1])) +\n",
    "      ' on the training data.')\n",
    "print('This classifier has a recall score of {}'.format(\n",
    "      recall_score(y_test['Successful Location'], gbc.predict(x_test_subset))) +\n",
    "      ', a precision score of {}'.format(\n",
    "      precision_score(y_test['Successful Location'], gbc.predict(x_test_subset))) +\n",
    "      ', and an area under receiver operating curve score of {:.2f}'.format(\n",
    "      roc_auc_score(y_test['Successful Location'], gbc.predict_proba(x_test_subset)[:,1])) +\n",
    "      ' on the test data.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But see no gain in doing this, so we'll try both our best set of linear predictors, and the features emphasized by the gradient boosted classifier on the full set of variables in evaluating a k nearest neighbors classifier, returning to our scaled data sets for this location based algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This classifier has a recall score of 0.48, a precision score of 0.8571428571428571, and an area under receiver operating curve score of 0.93 on the training data.\n",
      "This classifier has a recall score of 0.5, a precision score of 0.75, and an area under receiver operating curve score of 0.69 on the test data.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "x_train_subset = x_train_scaled[[\n",
    "    'Total Population', 'Undergrads and Grads',\n",
    "    'Diploma/GED attained', 'Above 100k Earners', 'Crime Counts',\n",
    "    'walk_score', 'transit_score', 'raw_visit_count']].copy()\n",
    "x_test_subset = x_test_scaled[[\n",
    "    'Total Population', 'Undergrads and Grads',\n",
    "    'Diploma/GED attained', 'Above 100k Earners', 'Crime Counts',\n",
    "    'walk_score', 'transit_score', 'raw_visit_count']].copy()\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors = 3)\n",
    "knn.fit(x_train_subset, y_train['Successful Location'])\n",
    "\n",
    "print('This classifier has a recall score of {}'.format(\n",
    "      recall_score(y_train['Successful Location'], knn.predict(x_train_subset))) +\n",
    "      ', a precision score of {}'.format(\n",
    "      precision_score(y_train['Successful Location'], knn.predict(x_train_subset))) +\n",
    "      ', and an area under receiver operating curve score of {:.2f}'.format(\n",
    "      roc_auc_score(y_train['Successful Location'], knn.predict_proba(x_train_subset)[:,1])) +\n",
    "      ' on the training data.')\n",
    "print('This classifier has a recall score of {}'.format(\n",
    "      recall_score(y_test['Successful Location'], knn.predict(x_test_subset))) +\n",
    "      ', a precision score of {}'.format(\n",
    "      precision_score(y_test['Successful Location'], knn.predict(x_test_subset))) +\n",
    "      ', and an area under receiver operating curve score of {:.2f}'.format(\n",
    "      roc_auc_score(y_test['Successful Location'], knn.predict_proba(x_test_subset)[:,1])) +\n",
    "      ' on the test data.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model is certainly not our best, so we try the gradient boosting emphasized variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This classifier has a recall score of 0.48, a precision score of 0.8, and an area under receiver operating curve score of 0.94 on the training data.\n",
      "This classifier has a recall score of 0.6666666666666666, a precision score of 1.0, and an area under receiver operating curve score of 0.78 on the test data.\n"
     ]
    }
   ],
   "source": [
    "x_train_subset = x_train_scaled[[\n",
    "    'Married Parent Households', 'Single Parent Households', 'Undergrads and Grads',\n",
    "    'Crime Counts', 'walk_score', 'raw_visit_count']].copy()\n",
    "x_test_subset = x_test_scaled[[\n",
    "    'Married Parent Households', 'Single Parent Households', 'Undergrads and Grads',\n",
    "    'Crime Counts', 'walk_score', 'raw_visit_count']].copy()\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors = 3)\n",
    "knn.fit(x_train_subset, y_train['Successful Location'])\n",
    "\n",
    "print('This classifier has a recall score of {}'.format(\n",
    "      recall_score(y_train['Successful Location'], knn.predict(x_train_subset))) +\n",
    "      ', a precision score of {}'.format(\n",
    "      precision_score(y_train['Successful Location'], knn.predict(x_train_subset))) +\n",
    "      ', and an area under receiver operating curve score of {:.2f}'.format(\n",
    "      roc_auc_score(y_train['Successful Location'], knn.predict_proba(x_train_subset)[:,1])) +\n",
    "      ' on the training data.')\n",
    "print('This classifier has a recall score of {}'.format(\n",
    "      recall_score(y_test['Successful Location'], knn.predict(x_test_subset))) +\n",
    "      ', a precision score of {}'.format(\n",
    "      precision_score(y_test['Successful Location'], knn.predict(x_test_subset))) +\n",
    "      ', and an area under receiver operating curve score of {:.2f}'.format(\n",
    "      roc_auc_score(y_test['Successful Location'], knn.predict_proba(x_test_subset)[:,1])) +\n",
    "      ' on the test data.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we get back to a precision of 1 on our test data, but our auc scores are still lacking behind our best models, so we try adding our previously emphasized variables from our best regressor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This classifier has a recall score of 0.6, a precision score of 0.9375, and an area under receiver operating curve score of 0.96 on the training data.\n",
      "This classifier has a recall score of 0.5, a precision score of 1.0, and an area under receiver operating curve score of 0.70 on the test data.\n"
     ]
    }
   ],
   "source": [
    "x_train_subset = x_train_scaled[[\n",
    "    'Married Parent Households', 'Single Parent Households', 'Undergrads and Grads',\n",
    "    'Crime Counts', 'walk_score', 'raw_visit_count', 'Households in Poverty', 'Below 40k Earners']].copy()\n",
    "x_test_subset = x_test_scaled[[\n",
    "    'Married Parent Households', 'Single Parent Households', 'Undergrads and Grads',\n",
    "    'Crime Counts', 'walk_score', 'raw_visit_count', 'Households in Poverty', 'Below 40k Earners']].copy()\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors = 3)\n",
    "knn.fit(x_train_subset, y_train['Successful Location'])\n",
    "\n",
    "print('This classifier has a recall score of {}'.format(\n",
    "      recall_score(y_train['Successful Location'], knn.predict(x_train_subset))) +\n",
    "      ', a precision score of {}'.format(\n",
    "      precision_score(y_train['Successful Location'], knn.predict(x_train_subset))) +\n",
    "      ', and an area under receiver operating curve score of {:.2f}'.format(\n",
    "      roc_auc_score(y_train['Successful Location'], knn.predict_proba(x_train_subset)[:,1])) +\n",
    "      ' on the training data.')\n",
    "print('This classifier has a recall score of {}'.format(\n",
    "      recall_score(y_test['Successful Location'], knn.predict(x_test_subset))) +\n",
    "      ', a precision score of {}'.format(\n",
    "      precision_score(y_test['Successful Location'], knn.predict(x_test_subset))) +\n",
    "      ', and an area under receiver operating curve score of {:.2f}'.format(\n",
    "      roc_auc_score(y_test['Successful Location'], knn.predict_proba(x_test_subset)[:,1])) +\n",
    "      ' on the test data.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The notably higher precision on the training data here may actually make this a more preferable model since we emphasize the value of precision, even as our recall falls on our test data, but we're still not beating our gradient boosting model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just for one last point we see if we produce a better model with a union of the linear and gradient boosting variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This classifier has a recall score of 0.4, a precision score of 0.8333333333333334, and an area under receiver operating curve score of 0.94 on the training data.\n",
      "This classifier has a recall score of 0.5, a precision score of 1.0, and an area under receiver operating curve score of 0.70 on the test data.\n"
     ]
    }
   ],
   "source": [
    "x_train_subset = x_train_scaled[[\n",
    "    'Total Population',\n",
    "    'Married Parent Households', 'Single Parent Households', 'Undergrads and Grads',\n",
    "    'Renter Occupied Households', 'Diploma/GED attained', 'Above 100k Earners',\n",
    "    'Crime Counts', 'walk_score', 'transit_score', 'raw_visit_count']].copy()\n",
    "x_test_subset = x_test_scaled[[\n",
    "    'Total Population',\n",
    "    'Married Parent Households', 'Single Parent Households', 'Undergrads and Grads',\n",
    "    'Renter Occupied Households', 'Diploma/GED attained', 'Above 100k Earners',\n",
    "    'Crime Counts', 'walk_score', 'transit_score', 'raw_visit_count']].copy()\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors = 3)\n",
    "knn.fit(x_train_subset, y_train['Successful Location'])\n",
    "\n",
    "print('This classifier has a recall score of {}'.format(\n",
    "      recall_score(y_train['Successful Location'], knn.predict(x_train_subset))) +\n",
    "      ', a precision score of {}'.format(\n",
    "      precision_score(y_train['Successful Location'], knn.predict(x_train_subset))) +\n",
    "      ', and an area under receiver operating curve score of {:.2f}'.format(\n",
    "      roc_auc_score(y_train['Successful Location'], knn.predict_proba(x_train_subset)[:,1])) +\n",
    "      ' on the training data.')\n",
    "print('This classifier has a recall score of {}'.format(\n",
    "      recall_score(y_test['Successful Location'], knn.predict(x_test_subset))) +\n",
    "      ', a precision score of {}'.format(\n",
    "      precision_score(y_test['Successful Location'], knn.predict(x_test_subset))) +\n",
    "      ', and an area under receiver operating curve score of {:.2f}'.format(\n",
    "      roc_auc_score(y_test['Successful Location'], knn.predict_proba(x_test_subset)[:,1])) +\n",
    "      ' on the test data.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we lost on recall scores for both training and test data, so it seem we do better with the gradient boosted chosen variables. We'll keep the better variable set then, and see if we can summarize something more generalizeable from PCA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 8 artists>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# First lets examine contribution to variance\n",
    "# on each component\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "x_train_subset = x_train_scaled[[\n",
    "    'Married Parent Households', 'Single Parent Households', 'Undergrads and Grads',\n",
    "    'Crime Counts', 'walk_score', 'raw_visit_count', 'Households in Poverty', 'Below 40k Earners']].copy()\n",
    "x_test_subset = x_test_scaled[[\n",
    "    'Married Parent Households', 'Single Parent Households', 'Undergrads and Grads',\n",
    "    'Crime Counts', 'walk_score', 'raw_visit_count', 'Households in Poverty', 'Below 40k Earners']].copy()\n",
    "\n",
    "pca = PCA()\n",
    "pca.fit(x_train_subset)\n",
    "plt.bar(np.arange(len(pca.explained_variance_ratio_)), pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems we have the greatest fall off in explained variance after the 6th component, so we try predicting with this many components, still using the knn classifier which has given us the most success thus far."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This classifier has a recall score of 0.52, a precision score of 0.9285714285714286, and an area under receiver operating curve score of 0.95 on the training data.\n",
      "This classifier has a recall score of 0.5, a precision score of 0.75, and an area under receiver operating curve score of 0.70 on the test data.\n"
     ]
    }
   ],
   "source": [
    "pca = PCA(n_components=6)\n",
    "x_train_pca = pca.fit(x_train_subset)\n",
    "x_train_pca = pca.transform(x_train_subset)\n",
    "x_test_pca = pca.transform(x_test_subset)\n",
    "\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors = 3)\n",
    "knn.fit(x_train_pca, y_train['Successful Location'])\n",
    "\n",
    "print('This classifier has a recall score of {}'.format(\n",
    "      recall_score(y_train['Successful Location'], knn.predict(x_train_pca))) +\n",
    "      ', a precision score of {}'.format(\n",
    "      precision_score(y_train['Successful Location'], knn.predict(x_train_pca))) +\n",
    "      ', and an area under receiver operating curve score of {:.2f}'.format(\n",
    "      roc_auc_score(y_train['Successful Location'], knn.predict_proba(x_train_pca)[:,1])) +\n",
    "      ' on the training data.')\n",
    "print('This classifier has a recall score of {}'.format(\n",
    "      recall_score(y_test['Successful Location'], knn.predict(x_test_pca))) +\n",
    "      ', a precision score of {}'.format(\n",
    "      precision_score(y_test['Successful Location'], knn.predict(x_test_pca))) +\n",
    "      ', and an area under receiver operating curve score of {:.2f}'.format(\n",
    "      roc_auc_score(y_test['Successful Location'], knn.predict_proba(x_test_pca)[:,1])) +\n",
    "      ' on the test data.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But a loss in precision turns us away from using PCA for our model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before seeing how we can cluster on various features, we have one more available non linear classification algorithm to try. We'll try a Gaussian NaiveBayes approach on our unscaled data using our two better performing variable subsets that produced our best models above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This classifier has a recall score of 0.44, a precision score of 0.55, and an area under receiver operating curve score of 0.82 on the training data.\n",
      "This classifier has a recall score of 0.5, a precision score of 0.6, and an area under receiver operating curve score of 0.90 on the test data.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "x_train_subset = x_train[[\n",
    "    'Total Population', 'Undergrads and Grads',\n",
    "    'Diploma/GED attained', 'Above 100k Earners', 'Crime Counts',\n",
    "    'walk_score', 'transit_score', 'raw_visit_count']].copy()\n",
    "x_test_subset = x_test[[\n",
    "    'Total Population', 'Undergrads and Grads',\n",
    "    'Diploma/GED attained', 'Above 100k Earners', 'Crime Counts',\n",
    "    'walk_score', 'transit_score', 'raw_visit_count']].copy()\n",
    "\n",
    "gnb = GaussianNB()\n",
    "gnb.fit(x_train_subset, y_train['Successful Location'])\n",
    "\n",
    "print('This classifier has a recall score of {}'.format(\n",
    "      recall_score(y_train['Successful Location'], gnb.predict(x_train_subset))) +\n",
    "      ', a precision score of {}'.format(\n",
    "      precision_score(y_train['Successful Location'], gnb.predict(x_train_subset))) +\n",
    "      ', and an area under receiver operating curve score of {:.2f}'.format(\n",
    "      roc_auc_score(y_train['Successful Location'], gnb.predict_proba(x_train_subset)[:,1])) +\n",
    "      ' on the training data.')\n",
    "print('This classifier has a recall score of {}'.format(\n",
    "      recall_score(y_test['Successful Location'], gnb.predict(x_test_subset))) +\n",
    "      ', a precision score of {}'.format(\n",
    "      precision_score(y_test['Successful Location'], gnb.predict(x_test_subset))) +\n",
    "      ', and an area under receiver operating curve score of {:.2f}'.format(\n",
    "      roc_auc_score(y_test['Successful Location'], gnb.predict_proba(x_test_subset)[:,1])) +\n",
    "      ' on the test data.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This classifier has a recall score of 0.4, a precision score of 0.5263157894736842, and an area under receiver operating curve score of 0.75 on the training data.\n",
      "This classifier has a recall score of 0.5, a precision score of 0.6, and an area under receiver operating curve score of 0.90 on the test data.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "x_train_subset = x_train[[\n",
    "    'Married Parent Households', 'Single Parent Households', 'Undergrads and Grads',\n",
    "    'Crime Counts', 'walk_score', 'raw_visit_count']].copy()\n",
    "x_test_subset = x_test[[\n",
    "    'Married Parent Households', 'Single Parent Households', 'Undergrads and Grads',\n",
    "    'Crime Counts', 'walk_score', 'raw_visit_count']].copy()\n",
    "\n",
    "gnb = GaussianNB()\n",
    "gnb.fit(x_train_subset, y_train['Successful Location'])\n",
    "\n",
    "print('This classifier has a recall score of {}'.format(\n",
    "      recall_score(y_train['Successful Location'], gnb.predict(x_train_subset))) +\n",
    "      ', a precision score of {}'.format(\n",
    "      precision_score(y_train['Successful Location'], gnb.predict(x_train_subset))) +\n",
    "      ', and an area under receiver operating curve score of {:.2f}'.format(\n",
    "      roc_auc_score(y_train['Successful Location'], gnb.predict_proba(x_train_subset)[:,1])) +\n",
    "      ' on the training data.')\n",
    "print('This classifier has a recall score of {}'.format(\n",
    "      recall_score(y_test['Successful Location'], gnb.predict(x_test_subset))) +\n",
    "      ', a precision score of {}'.format(\n",
    "      precision_score(y_test['Successful Location'], gnb.predict(x_test_subset))) +\n",
    "      ', and an area under receiver operating curve score of {:.2f}'.format(\n",
    "      roc_auc_score(y_test['Successful Location'], gnb.predict_proba(x_test_subset)[:,1])) +\n",
    "      ' on the test data.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But we simply don't get a good model from the GaussianNB classifiers. At the end a prediction of successful from our RandomForestClassifier with the subset of variables we got from Lasso best predicts successful locations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unsupervised Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now turn to clustering our different Census Block Groups. Our primary interest in this segmentation is to produce clusters where fast food consumption is high, as these will be our target customer segments.\n",
    "\n",
    "We will cluster on the entire data set first and see if any cluster comes out with distinctly higher amounts of successful fast food locations. If so we want to record any other trends we can find in that cluster.\n",
    "\n",
    "We will then follow up clustering on just our best predicting PCA vectors, than map any successful clusters points back to their original observations and again look for trends."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fd56ef31610>]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "cluster_sses = []\n",
    "for i in range(2,15):\n",
    "    kme = KMeans(n_clusters = i, random_state=42)\n",
    "    kme.fit(x_train)\n",
    "    cluster_sses.append(kme.inertia_)\n",
    "\n",
    "plt.plot(np.arange(2,15), cluster_sses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The steep falls in Sum of Squares to the centroids going from 2 to 4 clusters indicateds there are likely at least this many intrinsic clusterings in the data, while the fall proceeding 4 clusters is much more shallow, so we choose 4 as our cluster count to segment on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>col_0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Successful Location</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>False</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>108</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>True</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "col_0                 0  1    2  3\n",
       "Successful Location               \n",
       "False                14  0  108  2\n",
       "True                  7  1   15  2"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kme = KMeans(n_clusters = 4, random_state=42)\n",
    "kme.fit(x_train)\n",
    "ct = pd.crosstab(y_train['Successful Location'], kme.predict(x_train))\n",
    "ct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The expected proportion of successful fast food locations is 0.16778523489932887\n"
     ]
    }
   ],
   "source": [
    "print('The expected proportion of successful fast food locations is {}'.format(\n",
    "    y_train['Successful Location'].sum() / len(y_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We do seem to have segmented off populations that are more likely to attract fast food visitors. Lets compare the centers of each population to see if the less successful cluster 2 stands out from the other three variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Total Population</th>\n",
       "      <th>Pop. that Works from Home</th>\n",
       "      <th>Single Occupant Households</th>\n",
       "      <th>Single Parent Households</th>\n",
       "      <th>Married Parent Households</th>\n",
       "      <th>Undergrads and Grads</th>\n",
       "      <th>Diploma/GED attained</th>\n",
       "      <th>Degree attained</th>\n",
       "      <th>Households in Poverty</th>\n",
       "      <th>Below 40k Earners</th>\n",
       "      <th>40k-100k Earners</th>\n",
       "      <th>Above 100k Earners</th>\n",
       "      <th>Unemployed</th>\n",
       "      <th>Renter Occupied Households</th>\n",
       "      <th>Owner Occupied Households</th>\n",
       "      <th>Crime Counts</th>\n",
       "      <th>walk_score</th>\n",
       "      <th>transit_score</th>\n",
       "      <th>raw_visit_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1510.761905</td>\n",
       "      <td>24.190476</td>\n",
       "      <td>318.714286</td>\n",
       "      <td>29.761905</td>\n",
       "      <td>61.285714</td>\n",
       "      <td>239.238095</td>\n",
       "      <td>296.428571</td>\n",
       "      <td>401.809524</td>\n",
       "      <td>647.380952</td>\n",
       "      <td>292.190476</td>\n",
       "      <td>209.952381</td>\n",
       "      <td>145.238095</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>383.666667</td>\n",
       "      <td>263.714286</td>\n",
       "      <td>370.380952</td>\n",
       "      <td>76.142857</td>\n",
       "      <td>72.190476</td>\n",
       "      <td>1.658243e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2451.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>602.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>418.000000</td>\n",
       "      <td>558.000000</td>\n",
       "      <td>604.000000</td>\n",
       "      <td>874.000000</td>\n",
       "      <td>432.000000</td>\n",
       "      <td>262.000000</td>\n",
       "      <td>180.000000</td>\n",
       "      <td>119.000000</td>\n",
       "      <td>824.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>1877.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>1.875000e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1289.178862</td>\n",
       "      <td>19.609756</td>\n",
       "      <td>185.170732</td>\n",
       "      <td>61.479675</td>\n",
       "      <td>56.674797</td>\n",
       "      <td>187.991870</td>\n",
       "      <td>253.430894</td>\n",
       "      <td>231.504065</td>\n",
       "      <td>475.756098</td>\n",
       "      <td>220.227642</td>\n",
       "      <td>168.918699</td>\n",
       "      <td>86.609756</td>\n",
       "      <td>67.357724</td>\n",
       "      <td>235.747967</td>\n",
       "      <td>240.008130</td>\n",
       "      <td>139.252033</td>\n",
       "      <td>81.585366</td>\n",
       "      <td>71.146341</td>\n",
       "      <td>4.548543e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1597.750000</td>\n",
       "      <td>85.750000</td>\n",
       "      <td>530.000000</td>\n",
       "      <td>5.500000</td>\n",
       "      <td>39.500000</td>\n",
       "      <td>206.000000</td>\n",
       "      <td>91.500000</td>\n",
       "      <td>949.000000</td>\n",
       "      <td>959.500000</td>\n",
       "      <td>185.750000</td>\n",
       "      <td>372.000000</td>\n",
       "      <td>401.750000</td>\n",
       "      <td>47.750000</td>\n",
       "      <td>545.000000</td>\n",
       "      <td>414.500000</td>\n",
       "      <td>770.250000</td>\n",
       "      <td>94.250000</td>\n",
       "      <td>95.250000</td>\n",
       "      <td>3.606030e+05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Total Population  Pop. that Works from Home  Single Occupant Households  \\\n",
       "0       1510.761905                  24.190476                  318.714286   \n",
       "1       2451.000000                  36.000000                  602.000000   \n",
       "2       1289.178862                  19.609756                  185.170732   \n",
       "3       1597.750000                  85.750000                  530.000000   \n",
       "\n",
       "   Single Parent Households  Married Parent Households  Undergrads and Grads  \\\n",
       "0                 29.761905                  61.285714            239.238095   \n",
       "1                  0.000000                  29.000000            418.000000   \n",
       "2                 61.479675                  56.674797            187.991870   \n",
       "3                  5.500000                  39.500000            206.000000   \n",
       "\n",
       "   Diploma/GED attained  Degree attained  Households in Poverty  \\\n",
       "0            296.428571       401.809524             647.380952   \n",
       "1            558.000000       604.000000             874.000000   \n",
       "2            253.430894       231.504065             475.756098   \n",
       "3             91.500000       949.000000             959.500000   \n",
       "\n",
       "   Below 40k Earners  40k-100k Earners  Above 100k Earners  Unemployed  \\\n",
       "0         292.190476        209.952381          145.238095   56.000000   \n",
       "1         432.000000        262.000000          180.000000  119.000000   \n",
       "2         220.227642        168.918699           86.609756   67.357724   \n",
       "3         185.750000        372.000000          401.750000   47.750000   \n",
       "\n",
       "   Renter Occupied Households  Owner Occupied Households  Crime Counts  \\\n",
       "0                  383.666667                 263.714286    370.380952   \n",
       "1                  824.000000                  50.000000   1877.000000   \n",
       "2                  235.747967                 240.008130    139.252033   \n",
       "3                  545.000000                 414.500000    770.250000   \n",
       "\n",
       "   walk_score  transit_score  raw_visit_count  \n",
       "0   76.142857      72.190476     1.658243e+05  \n",
       "1   99.000000     100.000000     1.875000e+06  \n",
       "2   81.585366      71.146341     4.548543e+04  \n",
       "3   94.250000      95.250000     3.606030e+05  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "centers = pd.DataFrame(kme.cluster_centers_)\n",
    "centers.columns = x_train.columns\n",
    "centers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Judging cluster 2 as standing out when it is either the highest or lowest in a category, and defining our market segmentation for fast food restaurants as the opposite of cluster 2's position, we arrive at locations where fast food restaurants might have more appeal generally have populations with more:\n",
    "<li>Total Population</li>\n",
    "<li>Population that Works from Home</li>\n",
    "<li>Single Occupant Households</li>\n",
    "<li>Undergrads and Grads</li>\n",
    "<li>Degree Attained</li>\n",
    "<li>Households in Poverty</li>\n",
    "<li>40k-100k Earners</li>\n",
    "<li>Above 100k Earners</li>\n",
    "<li>Renter Occupied Households</li>\n",
    "<li>Crime Counts</li>\n",
    "<li>raw_visit_count</li>\n",
    "\n",
    "and fewer:\n",
    "<li>Single Parent Households</li>\n",
    "\n",
    "But having to keep in mind that our strongest aligned clusters are only 1 and 2 neighborhoods, which is not the sign of a good generalizable model. Lets instead cluster by our former PCA groupings which produced our most generalized model and if we get a better clustering, see what our segments look like then when we take it back to the full variable set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fd56f1049d0>]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "cluster_sses = []\n",
    "for i in range(2,10):\n",
    "    kme = KMeans(n_clusters = i, random_state=42)\n",
    "    kme.fit(x_train_pca)\n",
    "    cluster_sses.append(kme.inertia_)\n",
    "\n",
    "plt.plot(np.arange(2,10), cluster_sses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>col_0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Successful Location</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>False</td>\n",
       "      <td>16</td>\n",
       "      <td>14</td>\n",
       "      <td>64</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "col_0                 0   1   2   3  4  5\n",
       "Successful Location                      \n",
       "False                16  14  64  29  0  1\n",
       "True                  4   2   9   2  2  6"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kme = KMeans(n_clusters = 6, random_state=42)\n",
    "kme.fit(x_train_pca)\n",
    "ct = pd.crosstab(y_train['Successful Location'], kme.predict(x_train_pca))\n",
    "ct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here Cluster 5 looks like it will be a more trustworthy indicator of what makes an area attractive to fast food, so we'll align our original training set with these clusters and see if the in cluster means stand out for cluster 5 and 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Total Population</th>\n",
       "      <th>Pop. that Works from Home</th>\n",
       "      <th>Single Occupant Households</th>\n",
       "      <th>Single Parent Households</th>\n",
       "      <th>Married Parent Households</th>\n",
       "      <th>Undergrads and Grads</th>\n",
       "      <th>Diploma/GED attained</th>\n",
       "      <th>Degree attained</th>\n",
       "      <th>Households in Poverty</th>\n",
       "      <th>Below 40k Earners</th>\n",
       "      <th>40k-100k Earners</th>\n",
       "      <th>Above 100k Earners</th>\n",
       "      <th>Unemployed</th>\n",
       "      <th>Renter Occupied Households</th>\n",
       "      <th>Owner Occupied Households</th>\n",
       "      <th>Crime Counts</th>\n",
       "      <th>walk_score</th>\n",
       "      <th>transit_score</th>\n",
       "      <th>raw_visit_count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cluster</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1806.450000</td>\n",
       "      <td>22.900000</td>\n",
       "      <td>277.500000</td>\n",
       "      <td>46.400000</td>\n",
       "      <td>133.800000</td>\n",
       "      <td>103.550000</td>\n",
       "      <td>484.350000</td>\n",
       "      <td>337.900000</td>\n",
       "      <td>751.750000</td>\n",
       "      <td>288.550000</td>\n",
       "      <td>315.250000</td>\n",
       "      <td>147.950000</td>\n",
       "      <td>81.950000</td>\n",
       "      <td>307.400000</td>\n",
       "      <td>444.350000</td>\n",
       "      <td>142.450000</td>\n",
       "      <td>55.550000</td>\n",
       "      <td>52.800000</td>\n",
       "      <td>6.458595e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1556.250000</td>\n",
       "      <td>53.625000</td>\n",
       "      <td>514.312500</td>\n",
       "      <td>11.937500</td>\n",
       "      <td>43.062500</td>\n",
       "      <td>310.125000</td>\n",
       "      <td>159.000000</td>\n",
       "      <td>721.000000</td>\n",
       "      <td>881.312500</td>\n",
       "      <td>301.250000</td>\n",
       "      <td>276.875000</td>\n",
       "      <td>303.187500</td>\n",
       "      <td>50.437500</td>\n",
       "      <td>637.562500</td>\n",
       "      <td>243.750000</td>\n",
       "      <td>372.812500</td>\n",
       "      <td>96.937500</td>\n",
       "      <td>93.375000</td>\n",
       "      <td>1.649044e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>958.054795</td>\n",
       "      <td>15.301370</td>\n",
       "      <td>143.013699</td>\n",
       "      <td>34.410959</td>\n",
       "      <td>45.013699</td>\n",
       "      <td>93.575342</td>\n",
       "      <td>205.246575</td>\n",
       "      <td>211.767123</td>\n",
       "      <td>369.301370</td>\n",
       "      <td>162.000000</td>\n",
       "      <td>131.479452</td>\n",
       "      <td>75.821918</td>\n",
       "      <td>53.643836</td>\n",
       "      <td>170.260274</td>\n",
       "      <td>199.041096</td>\n",
       "      <td>119.041096</td>\n",
       "      <td>83.863014</td>\n",
       "      <td>71.890411</td>\n",
       "      <td>5.123564e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1625.354839</td>\n",
       "      <td>9.483871</td>\n",
       "      <td>191.741935</td>\n",
       "      <td>145.580645</td>\n",
       "      <td>54.741935</td>\n",
       "      <td>96.967742</td>\n",
       "      <td>326.967742</td>\n",
       "      <td>153.032258</td>\n",
       "      <td>548.903226</td>\n",
       "      <td>332.419355</td>\n",
       "      <td>170.096774</td>\n",
       "      <td>46.387097</td>\n",
       "      <td>94.612903</td>\n",
       "      <td>279.806452</td>\n",
       "      <td>269.096774</td>\n",
       "      <td>233.645161</td>\n",
       "      <td>81.677419</td>\n",
       "      <td>68.548387</td>\n",
       "      <td>5.352410e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2210.500000</td>\n",
       "      <td>59.000000</td>\n",
       "      <td>784.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>26.500000</td>\n",
       "      <td>334.000000</td>\n",
       "      <td>348.500000</td>\n",
       "      <td>976.000000</td>\n",
       "      <td>1154.500000</td>\n",
       "      <td>384.000000</td>\n",
       "      <td>491.000000</td>\n",
       "      <td>279.500000</td>\n",
       "      <td>78.500000</td>\n",
       "      <td>768.500000</td>\n",
       "      <td>386.000000</td>\n",
       "      <td>1819.500000</td>\n",
       "      <td>99.500000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>1.182032e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1909.000000</td>\n",
       "      <td>64.857143</td>\n",
       "      <td>65.571429</td>\n",
       "      <td>9.285714</td>\n",
       "      <td>6.285714</td>\n",
       "      <td>1693.000000</td>\n",
       "      <td>39.142857</td>\n",
       "      <td>123.428571</td>\n",
       "      <td>200.714286</td>\n",
       "      <td>129.857143</td>\n",
       "      <td>49.714286</td>\n",
       "      <td>21.142857</td>\n",
       "      <td>45.571429</td>\n",
       "      <td>152.714286</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>211.142857</td>\n",
       "      <td>85.000000</td>\n",
       "      <td>89.285714</td>\n",
       "      <td>1.001040e+05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Total Population  Pop. that Works from Home  \\\n",
       "cluster                                                \n",
       "0             1806.450000                  22.900000   \n",
       "1             1556.250000                  53.625000   \n",
       "2              958.054795                  15.301370   \n",
       "3             1625.354839                   9.483871   \n",
       "4             2210.500000                  59.000000   \n",
       "5             1909.000000                  64.857143   \n",
       "\n",
       "         Single Occupant Households  Single Parent Households  \\\n",
       "cluster                                                         \n",
       "0                        277.500000                 46.400000   \n",
       "1                        514.312500                 11.937500   \n",
       "2                        143.013699                 34.410959   \n",
       "3                        191.741935                145.580645   \n",
       "4                        784.500000                  0.000000   \n",
       "5                         65.571429                  9.285714   \n",
       "\n",
       "         Married Parent Households  Undergrads and Grads  \\\n",
       "cluster                                                    \n",
       "0                       133.800000            103.550000   \n",
       "1                        43.062500            310.125000   \n",
       "2                        45.013699             93.575342   \n",
       "3                        54.741935             96.967742   \n",
       "4                        26.500000            334.000000   \n",
       "5                         6.285714           1693.000000   \n",
       "\n",
       "         Diploma/GED attained  Degree attained  Households in Poverty  \\\n",
       "cluster                                                                 \n",
       "0                  484.350000       337.900000             751.750000   \n",
       "1                  159.000000       721.000000             881.312500   \n",
       "2                  205.246575       211.767123             369.301370   \n",
       "3                  326.967742       153.032258             548.903226   \n",
       "4                  348.500000       976.000000            1154.500000   \n",
       "5                   39.142857       123.428571             200.714286   \n",
       "\n",
       "         Below 40k Earners  40k-100k Earners  Above 100k Earners  Unemployed  \\\n",
       "cluster                                                                        \n",
       "0               288.550000        315.250000          147.950000   81.950000   \n",
       "1               301.250000        276.875000          303.187500   50.437500   \n",
       "2               162.000000        131.479452           75.821918   53.643836   \n",
       "3               332.419355        170.096774           46.387097   94.612903   \n",
       "4               384.000000        491.000000          279.500000   78.500000   \n",
       "5               129.857143         49.714286           21.142857   45.571429   \n",
       "\n",
       "         Renter Occupied Households  Owner Occupied Households  Crime Counts  \\\n",
       "cluster                                                                        \n",
       "0                        307.400000                 444.350000    142.450000   \n",
       "1                        637.562500                 243.750000    372.812500   \n",
       "2                        170.260274                 199.041096    119.041096   \n",
       "3                        279.806452                 269.096774    233.645161   \n",
       "4                        768.500000                 386.000000   1819.500000   \n",
       "5                        152.714286                  48.000000    211.142857   \n",
       "\n",
       "         walk_score  transit_score  raw_visit_count  \n",
       "cluster                                              \n",
       "0         55.550000      52.800000     6.458595e+04  \n",
       "1         96.937500      93.375000     1.649044e+05  \n",
       "2         83.863014      71.890411     5.123564e+04  \n",
       "3         81.677419      68.548387     5.352410e+04  \n",
       "4         99.500000     100.000000     1.182032e+06  \n",
       "5         85.000000      89.285714     1.001040e+05  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca_cluster = x_train.copy()\n",
    "pca_cluster['cluster'] = kme.predict(x_train_pca)\n",
    "pca_cluster.groupby('cluster').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assuming we have two distinct clusterings, first we can look at the clustering for cluster 5 and determine that the description of one of our target segment neighborhoods is that it:\n",
    "Has a high count of:\n",
    "<li>Population that Works from Home</li>\n",
    "<li>Undergrads and Grads</li>\n",
    "    \n",
    "And low count of:\n",
    "<li>Single Occupant Households</li>\n",
    "<li>Single Parent Households</li>\n",
    "<li>Married Parent Households</li>\n",
    "<li>Diploma/GED as Highest Educational Attainment</li>\n",
    "<li>Households in Poverty</li>\n",
    "<li>Income Earners of any Tier</li>\n",
    "<li>Owner Occupied Households</li>\n",
    "\n",
    "Which all correlates fairly well with a high population of higher education students.\n",
    "\n",
    "Meanwhile Cluster 4 identifies another successful segment of neighborhoods as characterized by\n",
    "(and being mindful of higher population against which cluster charicterizations should be weighed)\n",
    "High:\n",
    "<li>Single Occupant Households</li>\n",
    "<li>Degree attained population</li>\n",
    "<li>Households in Poverty</li>\n",
    "<li>40-100k Earners</li>\n",
    "<li>Renter Occupied Households</li>\n",
    "<li>Crime Counts</li>\n",
    "<li>Walk Score</li>\n",
    "<li>transit_score</li>\n",
    "<li>raw_visit_count</li>\n",
    "\n",
    "Low:\n",
    "<li>Single Parent Households</li>\n",
    "<li>Married Parent Households</li>\n",
    "\n",
    "Which largely correlates with downtown. And we can summarize both market segments as:\n",
    "<li>Located Downtown OR near Universities</li>\n",
    "<li>Located in areas with high amounts of Single Occupant Households</li>\n",
    "<li>Located in areas with low amounts of families</li>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And having discovered clusters via KMeans we would also like to try hiearchichal clustering which can capture varying shapes of clusters which kMeans does not always excel at. Since we are trying to capture shapes that may not exactly cluster about their means, we'll need another way to determine cluster count besides sum of square residuals. We choose to plot our points using SNE and see if we can observe any particular groupings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7fd56ee25610>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "\n",
    "tsne = TSNE(random_state=42)\n",
    "x_train_sne = tsne.fit_transform(x_train)\n",
    "\n",
    "plt.scatter(x_train_sne[:,0], x_train_sne[:,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There aren't clear groupings in this examination, but going by larger gaps of white space it appears there are about 5 clusters, so we'll feed this to our agglomerative clustering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>col_0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Successful Location</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>False</td>\n",
       "      <td>106</td>\n",
       "      <td>11</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>True</td>\n",
       "      <td>13</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "col_0                  0   1  2  3  4\n",
       "Successful Location                  \n",
       "False                106  11  7  0  0\n",
       "True                  13   7  3  1  1"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.cluster import AgglomerativeClustering\n",
    "\n",
    "\n",
    "ac = AgglomerativeClustering(n_clusters = 5, linkage='ward')\n",
    "ct = pd.crosstab(y_train['Successful Location'], ac.fit_predict(x_train))\n",
    "ct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But this scheme fails to seperate out any predominantly Successful segmentation, so we are inclined to settle on our prior kmeans clusters as the best indicator for our customer segmentation. First however we will try one more clustering algorithm that may identify different cluster shapes, we'll do a run with DBSCAN and we'll use adjusted_rand_score to rate different parameters for our implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eps: 0.1, cluster_count: 0, rand_score: 1.0\n",
      "eps: 0.2, cluster_count: 0, rand_score: 1.0\n",
      "eps: 0.30000000000000004, cluster_count: 0, rand_score: 1.0\n",
      "eps: 0.4, cluster_count: 0, rand_score: 1.0\n",
      "eps: 0.5, cluster_count: 0, rand_score: 1.0\n",
      "eps: 0.6, cluster_count: 1, rand_score: 1.0\n",
      "eps: 0.7000000000000001, cluster_count: 2, rand_score: -0.051546391752577345\n",
      "eps: 0.8, cluster_count: 2, rand_score: -0.03125\n",
      "eps: 0.9, cluster_count: 2, rand_score: -0.012124669128998936\n",
      "eps: 1.0, cluster_count: 1, rand_score: 1.0\n",
      "eps: 1.1, cluster_count: 1, rand_score: 1.0\n",
      "eps: 1.2000000000000002, cluster_count: 1, rand_score: 1.0\n",
      "eps: 1.3000000000000003, cluster_count: 1, rand_score: 1.0\n",
      "eps: 1.4000000000000001, cluster_count: 1, rand_score: 1.0\n",
      "eps: 1.5000000000000002, cluster_count: 1, rand_score: 1.0\n",
      "eps: 1.6, cluster_count: 1, rand_score: 1.0\n",
      "eps: 1.7000000000000002, cluster_count: 1, rand_score: 1.0\n",
      "eps: 1.8000000000000003, cluster_count: 1, rand_score: 1.0\n",
      "eps: 1.9000000000000001, cluster_count: 1, rand_score: 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.metrics.cluster import adjusted_rand_score\n",
    "from numpy.random import RandomState\n",
    "\n",
    "rand_state = RandomState(seed=42)\n",
    "\n",
    "for i in np.arange(0.1,2,0.1):\n",
    "    dbs = DBSCAN(eps=i)\n",
    "    pred = dbs.fit_predict(x_train_pca)\n",
    "    pred = pred[pred != -1] # remove noise points\n",
    "    cluster_count = len(np.unique(pred))\n",
    "    rand_clustering = rand_state.randint(low=0, high=cluster_count, size=len(pred))\n",
    "    print(\"eps: {}, cluster_count: {}, rand_score: {}\".format(\n",
    "        i, cluster_count, adjusted_rand_score(pred, rand_clustering)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But our rand scores are negative even for runs where we achieve a clustering, so we should continue to stick with kmeans."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
