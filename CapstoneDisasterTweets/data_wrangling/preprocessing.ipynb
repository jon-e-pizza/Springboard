{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data wrangling for Our Disaster Tweets\n",
    "\n",
    "As the input training data for this project is coming out of a Kaggle competition, it is already gathered in it's entirety (and fairly well wrangled). Instead of gathering and combination, our focus will be on processing our data with machine learning techniques to accurately predict the concern that a tweet should merit. To prepare for this process, while our input tweet training set is as complete as it will be coming in, the models we will use will benefit from additional features that can be derived from the data:\n",
    "\n",
    "1. Processed Tweet texts\n",
    " - with tokens with low predictive value such as stop words or punctuation removed\n",
    " - with remaining tokens lemmatized for increased token predictive value across the corpus\n",
    " - with common bigrams ajoined for increased predictive value\n",
    "2. Primary likely topic of the tweet \n",
    "3. Representation of tweets in TF-IDF vector form\n",
    "\n",
    "The first of these two steps will be appended to our original data set to produce an ammended CSV, the third step set of features will be stored in a seperate CSV to maintain readability of the first file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check for Consistency\n",
    "\n",
    "Before performing our feature engineering steps, we should first do a sanity check on our incoming data to make sure we have the inputs we expect. First, all tweets should have an integer 0 or 1 in their 'target' column indicating whether the tweet is a disaster or not, and second, all tweet samples should have a string object in their text column. If any sample lacks either of these features they should be removed from our data set before we begin our feature engineering.\n",
    "\n",
    "Some subset of tweets also include keyword and location, but as they are not required, we will not be filtering our samples based on these fields. We may use keywords as a predictive variable in our machine learning step later, while we will pass over the location variable as not being relevant to our problem of automating answering whether the text of a tweet indicates it deserves attention from human emergency response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "tweet_df = pd.read_csv('../data/kaggle_training.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7613 entries, 0 to 7612\n",
      "Data columns (total 5 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   id        7613 non-null   int64 \n",
      " 1   keyword   7552 non-null   object\n",
      " 2   location  5080 non-null   object\n",
      " 3   text      7613 non-null   object\n",
      " 4   target    7613 non-null   int64 \n",
      "dtypes: int64(2), object(3)\n",
      "memory usage: 297.5+ KB\n"
     ]
    }
   ],
   "source": [
    "# check if we have nulls in our columns\n",
    "tweet_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 of the text entries are empty\n",
      "0 tweets aren't correctly targeted\n"
     ]
    }
   ],
   "source": [
    "# no nulls, but lets verify fields aren't otherwise invalid\n",
    "print(\"{} of the text entries are empty\".format(\n",
    "    len(tweet_df[tweet_df.text.str.len() == 0])))\n",
    "print(\"{} tweets aren't correctly targeted\".format(\n",
    "    len(tweet_df[~((tweet_df.target == 0) | (tweet_df.target == 1))])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering\n",
    "\n",
    "### Tweet Processing\n",
    "\n",
    "Our fields are consistent, so it's time to start engineering our features. The first thing we aim to do is use our preprocessing toolkits to provide some normalization over our tweet texts. We'll be normalizing via stripping out white space, so called stop words ('the', 'a', etc.), and punctuation with little predictive value. We'll lemmatize remaining words after these filters to increase the amount of predictive information we can get from common terms, and then use phrase modeling to ajoin potential bigrams in our corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# We'll use Spacy for our tweet preprocessing, and add emoticons to our\n",
    "# pipeline so we don't remove them as simple punctuation tokens\n",
    "import spacy\n",
    "from spacyemoticon import Emoticon\n",
    "\n",
    "nlp = spacy.load('en_core_web_md')\n",
    "emoticon = Emoticon(nlp)\n",
    "nlp.add_pipe(emoticon, first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def keep_token(tok):\n",
    "    \"\"\" Filter out tokens without predictive value \"\"\"\n",
    "    return not (tok.lemma_ in spacy.lang.en.stop_words.STOP_WORDS\n",
    "                or tok.is_space\n",
    "                or (tok.is_punct and not tok._.is_emoticon))\n",
    "\n",
    "def left_hash(tok):\n",
    "    \"\"\"\n",
    "    Return hashtag if token is a hashtag\n",
    "\n",
    "    Words are used with slightly different emphasis when used as\n",
    "    hashtags, so we'll maintain this distinction post processing\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    tok : nlp.Token\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    string\n",
    "        Either a '#' character to be prepended to a recognized hashtag\n",
    "        token or empty string '' if not a hashtag\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if tok.nbor(-1).orth_ == '#':\n",
    "            return '#'\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    return ''\n",
    "\n",
    "def preprocess(nlp, tt):\n",
    "    parsed = nlp(tt)\n",
    "    return \" \".join([left_hash(token) + token.lemma_ for token in parsed\n",
    "                     if keep_token(token)])\n",
    "\n",
    "def df_preprocess(nlp, func):\n",
    "    return lambda text: func(nlp, text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "processed_tweets = tweet_df.text.apply(df_preprocess(nlp, preprocess))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do a quick consistency check on our process so far."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original</th>\n",
       "      <th>processed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>-PRON- deed reason #earthquake allah forgive -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>forest fire near la ronge sask canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>resident ask shelter place notify officer evac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>13,000 people receive #wildfir evacuation orde...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>send photo ruby #alaska smoke #wildfire pour s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>#RockyFire Update =&gt; California Hwy. 20 closed...</td>\n",
       "      <td>#rockyfire update = &gt; california hwy 20 close ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>#flood #disaster Heavy rain causes flash flood...</td>\n",
       "      <td>#flood #disaster heavy rain cause flash floodi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>I'm on top of the hill and I can see a fire in...</td>\n",
       "      <td>-PRON- hill -PRON- fire wood</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>There's an emergency evacuation happening now ...</td>\n",
       "      <td>emergency evacuation happen building street</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>I'm afraid that the tornado is coming to our a...</td>\n",
       "      <td>-PRON- afraid tornado come -PRON- area</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            original  \\\n",
       "0  Our Deeds are the Reason of this #earthquake M...   \n",
       "1             Forest fire near La Ronge Sask. Canada   \n",
       "2  All residents asked to 'shelter in place' are ...   \n",
       "3  13,000 people receive #wildfires evacuation or...   \n",
       "4  Just got sent this photo from Ruby #Alaska as ...   \n",
       "5  #RockyFire Update => California Hwy. 20 closed...   \n",
       "6  #flood #disaster Heavy rain causes flash flood...   \n",
       "7  I'm on top of the hill and I can see a fire in...   \n",
       "8  There's an emergency evacuation happening now ...   \n",
       "9  I'm afraid that the tornado is coming to our a...   \n",
       "\n",
       "                                           processed  \n",
       "0  -PRON- deed reason #earthquake allah forgive -...  \n",
       "1              forest fire near la ronge sask canada  \n",
       "2  resident ask shelter place notify officer evac...  \n",
       "3  13,000 people receive #wildfir evacuation orde...  \n",
       "4  send photo ruby #alaska smoke #wildfire pour s...  \n",
       "5  #rockyfire update = > california hwy 20 close ...  \n",
       "6  #flood #disaster heavy rain cause flash floodi...  \n",
       "7                       -PRON- hill -PRON- fire wood  \n",
       "8        emergency evacuation happen building street  \n",
       "9             -PRON- afraid tornado come -PRON- area  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({'original': tweet_df.text.head(10), 'processed': processed_tweets[:10]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our spacy preprocessing seems to have added in '-PRON-'s of unknown origin, we'll remove these before proceeding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_tweets = [tweet.replace('-PRON- ', '') for tweet in processed_tweets]\n",
    "processed_tweets = [tweet.replace(' -PRON-', '') for tweet in processed_tweets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original</th>\n",
       "      <th>processed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>deed reason #earthquake allah forgive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>forest fire near la ronge sask canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>resident ask shelter place notify officer evac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>13,000 people receive #wildfir evacuation orde...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>send photo ruby #alaska smoke #wildfire pour s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>#RockyFire Update =&gt; California Hwy. 20 closed...</td>\n",
       "      <td>#rockyfire update = &gt; california hwy 20 close ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>#flood #disaster Heavy rain causes flash flood...</td>\n",
       "      <td>#flood #disaster heavy rain cause flash floodi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>I'm on top of the hill and I can see a fire in...</td>\n",
       "      <td>hill fire wood</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>There's an emergency evacuation happening now ...</td>\n",
       "      <td>emergency evacuation happen building street</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>I'm afraid that the tornado is coming to our a...</td>\n",
       "      <td>afraid tornado come area</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            original  \\\n",
       "0  Our Deeds are the Reason of this #earthquake M...   \n",
       "1             Forest fire near La Ronge Sask. Canada   \n",
       "2  All residents asked to 'shelter in place' are ...   \n",
       "3  13,000 people receive #wildfires evacuation or...   \n",
       "4  Just got sent this photo from Ruby #Alaska as ...   \n",
       "5  #RockyFire Update => California Hwy. 20 closed...   \n",
       "6  #flood #disaster Heavy rain causes flash flood...   \n",
       "7  I'm on top of the hill and I can see a fire in...   \n",
       "8  There's an emergency evacuation happening now ...   \n",
       "9  I'm afraid that the tornado is coming to our a...   \n",
       "\n",
       "                                           processed  \n",
       "0              deed reason #earthquake allah forgive  \n",
       "1              forest fire near la ronge sask canada  \n",
       "2  resident ask shelter place notify officer evac...  \n",
       "3  13,000 people receive #wildfir evacuation orde...  \n",
       "4  send photo ruby #alaska smoke #wildfire pour s...  \n",
       "5  #rockyfire update = > california hwy 20 close ...  \n",
       "6  #flood #disaster heavy rain cause flash floodi...  \n",
       "7                                     hill fire wood  \n",
       "8        emergency evacuation happen building street  \n",
       "9                           afraid tornado come area  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({'original': tweet_df.text.head(10), 'processed': processed_tweets[:10]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Much better, but before adding this processed column to our data frame, we'll ajoin likely bigram words using the gensim implementation of phrase modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from gensim.models import Phrases\n",
    "from gensim.models.word2vec import LineSentence\n",
    "\n",
    "bigramed_tweets = Phrases(processed_tweets)\n",
    "processed_tweets = pd.Series(\n",
    "    [''.join(bigramed_tweets[tweet]) for tweet in processed_tweets])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now we can add the processed tweets to our original dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tweet_df['processed_text'] = processed_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>processed_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>deed reason #earthquake allah forgive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>forest fire near la ronge sask canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>resident ask shelter place notify officer evac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>13,000 people receive #wildfir evacuation orde...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>send photo ruby #alaska smoke #wildfire pour s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>#RockyFire Update =&gt; California Hwy. 20 closed...</td>\n",
       "      <td>#rockyfire update = &gt; california hwy 20 close ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>#flood #disaster Heavy rain causes flash flood...</td>\n",
       "      <td>#flood #disaster heavy rain cause flash floodi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>I'm on top of the hill and I can see a fire in...</td>\n",
       "      <td>hill fire wood</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>There's an emergency evacuation happening now ...</td>\n",
       "      <td>emergency evacuation happen building street</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>I'm afraid that the tornado is coming to our a...</td>\n",
       "      <td>afraid tornado come area</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  Our Deeds are the Reason of this #earthquake M...   \n",
       "1             Forest fire near La Ronge Sask. Canada   \n",
       "2  All residents asked to 'shelter in place' are ...   \n",
       "3  13,000 people receive #wildfires evacuation or...   \n",
       "4  Just got sent this photo from Ruby #Alaska as ...   \n",
       "5  #RockyFire Update => California Hwy. 20 closed...   \n",
       "6  #flood #disaster Heavy rain causes flash flood...   \n",
       "7  I'm on top of the hill and I can see a fire in...   \n",
       "8  There's an emergency evacuation happening now ...   \n",
       "9  I'm afraid that the tornado is coming to our a...   \n",
       "\n",
       "                                      processed_text  \n",
       "0              deed reason #earthquake allah forgive  \n",
       "1              forest fire near la ronge sask canada  \n",
       "2  resident ask shelter place notify officer evac...  \n",
       "3  13,000 people receive #wildfir evacuation orde...  \n",
       "4  send photo ruby #alaska smoke #wildfire pour s...  \n",
       "5  #rockyfire update = > california hwy 20 close ...  \n",
       "6  #flood #disaster heavy rain cause flash floodi...  \n",
       "7                                     hill fire wood  \n",
       "8        emergency evacuation happen building street  \n",
       "9                           afraid tornado come area  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#do a sanity check on these entries\n",
    "tweet_df.head(10)[['text', 'processed_text']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Topic Modeling\n",
    "And next we will use LDA modeling, to obtain the most likely topics of each tweet. Each tweet will be converted to a bag of words format before being passed to gensims LDA implementation. After which each topics words will be assessed to assign topic names to the derived topic groupings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from gensim.corpora import Dictionary, MmCorpus\n",
    "from gensim.models.ldamulticore import LdaMulticore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tokened_tweets = processed_tweets.apply(lambda tweet: tweet.split(' '))\n",
    "pt_dictionary = Dictionary(tokened_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def pt_generator(pt_dict, tweets):\n",
    "    for tweet in tweets:\n",
    "        yield pt_dict.doc2bow(tweet)\n",
    "        \n",
    "MmCorpus.serialize(\n",
    "    '../data/pt_bow_corpus.mm',\n",
    "    pt_generator(pt_dictionary, tokened_tweets))\n",
    "\n",
    "tweet_mmcorpus = MmCorpus('../data/pt_bow_corpus.mm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter('ignore')\n",
    "    lda = LdaMulticore(tweet_mmcorpus,\n",
    "                       num_topics=25,\n",
    "                       id2word=pt_dictionary,\n",
    "                       workers=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lda.save('../data/lda_topic_models')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A bit of exploration shows us that it's difficult to derive names or themes for our topics though, likely due to the short length of using a text as short as tweets as documents. As a result we will save just the primary topic number as assigned by LDA to each of our tweets for possible predictive value, and potentially use our saved lda model for further exploration later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def explore_topic(topic_number, topn=25):\n",
    "    \"\"\"\n",
    "    accept a user-supplied topic number and\n",
    "    print out a formatted list of the top terms\n",
    "    \"\"\"\n",
    "        \n",
    "    print(u'{:20} {}'.format(u'term', u'frequency') + u'\\n')\n",
    "\n",
    "    for term, frequency in lda.show_topic(topic_number, topn=25):\n",
    "        print(u'{:20} {:.3f}'.format(term, round(frequency, 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "term                 frequency\n",
      "\n",
      "'s                   0.006\n",
      "like                 0.006\n",
      "officer              0.005\n",
      "kill                 0.005\n",
      "wound                0.005\n",
      "come                 0.005\n",
      "police               0.004\n",
      "wreck                0.004\n",
      "suspect              0.004\n",
      "fire                 0.004\n",
      "storm                0.004\n",
      "large                0.003\n",
      "fucking              0.003\n",
      "violent              0.003\n",
      "exchange             0.003\n",
      "video                0.003\n",
      "bomb                 0.003\n",
      "news                 0.003\n",
      "tornado              0.003\n",
      "wreckage             0.003\n",
      "life                 0.003\n",
      "lake                 0.002\n",
      "richmond             0.002\n",
      "gunfire              0.002\n",
      "whirlwind            0.002\n"
     ]
    }
   ],
   "source": [
    "explore_topic(1, topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "term                 frequency\n",
      "\n",
      "'s                   0.007\n",
      "like                 0.005\n",
      "video                0.004\n",
      "wreck                0.004\n",
      "people               0.004\n",
      "love                 0.004\n",
      "think                0.004\n",
      "movie                0.004\n",
      "hollywood            0.004\n",
      "s                    0.003\n",
      "release              0.003\n",
      "weapon               0.003\n",
      "chile                0.003\n",
      "snowstorm            0.003\n",
      "thunder              0.003\n",
      "sink                 0.003\n",
      "trouble              0.003\n",
      "land                 0.003\n",
      "hear                 0.003\n",
      "3                    0.003\n",
      "storm                0.003\n",
      "good                 0.002\n",
      "come                 0.002\n",
      "look                 0.002\n",
      "violent              0.002\n"
     ]
    }
   ],
   "source": [
    "explore_topic(2, topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "topics = [lda[pt_dictionary.doc2bow(tweet)][0][0] for tweet in tokened_tweets]\n",
    "tweet_df['primary_topic'] = pd.Series(topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>processed_text</th>\n",
       "      <th>primary_topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "      <td>deed reason #earthquake allah forgive</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "      <td>forest fire near la ronge sask canada</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "      <td>resident ask shelter place notify officer evac...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "      <td>13,000 people receive #wildfir evacuation orde...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "      <td>send photo ruby #alaska smoke #wildfire pour s...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
       "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
       "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
       "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
       "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
       "\n",
       "   target                                     processed_text  primary_topic  \n",
       "0       1              deed reason #earthquake allah forgive              6  \n",
       "1       1              forest fire near la ronge sask canada             18  \n",
       "2       1  resident ask shelter place notify officer evac...              1  \n",
       "3       1  13,000 people receive #wildfir evacuation orde...              2  \n",
       "4       1  send photo ruby #alaska smoke #wildfire pour s...              9  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# verify state of dataframe\n",
    "tweet_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "And with that we'll save out our modified dataframe before constructing our tf-idf file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_df.to_csv('../data/processed_kaggle_training.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF\n",
    "Term frequency x Inverse Document Frequency is a representation similar to bag of words, but instead of being a direct count of term, it weighs each terms across their appearence in an entire corpus. This serves to add a measure of term importance to each term in a document when storing that bag of words doesn't have, as well as scaling the representations in each document vector to values that tend to yield better results when ran through various machine models.\n",
    "\n",
    "This time we will use a library provided by sklearn to vectorize our corpus before writing them to a seperate data file (this time for storage of a sparse matrix which is the typical form of this corpus)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidvectorizer = TfidfVectorizer(min_df=4, max_df=0.8)\n",
    "Xtfidf = tfidvectorizer.fit_transform(tweet_df['processed_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.sparse\n",
    "scipy.sparse.save_npz('../data/tweets-tf-idf.npz', Xtfidf)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
